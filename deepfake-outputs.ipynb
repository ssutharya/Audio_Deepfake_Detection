{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8130934,"sourceType":"datasetVersion","datasetId":4555568},{"sourceId":8171572,"sourceType":"datasetVersion","datasetId":4836275},{"sourceId":9810274,"sourceType":"datasetVersion","datasetId":6013837}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install kaggle numpy pandas librosa torchaudio torch torchvision scikit-learn tqdm matplotlib seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:17:03.605485Z","iopub.execute_input":"2025-04-24T08:17:03.606002Z","iopub.status.idle":"2025-04-24T08:17:06.957916Z","shell.execute_reply.started":"2025-04-24T08:17:03.605976Z","shell.execute_reply":"2025-04-24T08:17:06.956725Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.1)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\nRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.1.0)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\nRequirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.1)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Directories clean-up","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Directory to clean\noutput_dir = \"/kaggle/working/preprocessed_t2_test_chunks\"\n\n# Check if the directory exists and delete its contents\nif os.path.exists(output_dir):\n    print(f\"Clearing existing files in {output_dir}...\")\n    shutil.rmtree(output_dir)\n    print(f\"Deleted {output_dir} and all its contents.\")\nelse:\n    print(f\"Directory {output_dir} does not exist yet.\")\n\n# Recreate the directory\nos.makedirs(output_dir, exist_ok=True)\nprint(f\"Recreated empty directory: {output_dir}\")\n\n# Verification\nfiles = os.listdir(output_dir)\nprint(f\"Files in {output_dir} after clearing: {files}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:17:06.959758Z","iopub.execute_input":"2025-04-24T08:17:06.960032Z","iopub.status.idle":"2025-04-24T08:17:06.966915Z","shell.execute_reply.started":"2025-04-24T08:17:06.960007Z","shell.execute_reply":"2025-04-24T08:17:06.966255Z"}},"outputs":[{"name":"stdout","text":"Directory /kaggle/working/preprocessed_t2_test_chunks does not exist yet.\nRecreated empty directory: /kaggle/working/preprocessed_t2_test_chunks\nFiles in /kaggle/working/preprocessed_t2_test_chunks after clearing: []\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Data Preprocessing: MFCC, LFCC, Chroma-STFT","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torchaudio\nfrom torchaudio.transforms import MFCC, LFCC, Spectrogram\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}, GPU: {torch.cuda.get_device_name(0)}\")\n\n# Paths\nDATASET_PATHS = {\n    \"fake_or_real\": \"/kaggle/input/the-fake-or-real-dataset/\",\n    \"wild_deepfake\": \"/kaggle/input/in-the-wild-audio-deepfake/\"\n}\n\n# Function to validate if a .wav file can be loaded\ndef validate_wav_file(file_path):\n    try:\n        waveform, sr = torchaudio.load(file_path)\n        if waveform.size(1) == 0:\n            print(f\"Skipping empty file: {file_path}\")\n            return False\n        return True\n    except Exception as e:\n        print(f\"Skipping invalid file: {file_path}, Error: {e}\")\n        return False\n\n# Function to collect audio files and assign labels\ndef get_audio_files_and_labels():\n    audio_files = []\n    labels = []\n    counts = {\"fake\": 0, \"real\": 0}\n\n    # Process In-the-Wild dataset\n    wild_path = DATASET_PATHS[\"wild_deepfake\"]\n    wild_real_path = os.path.join(wild_path, \"release_in_the_wild\", \"real\")\n    wild_fake_path = os.path.join(wild_path, \"release_in_the_wild\", \"fake\")\n\n    for file in os.listdir(wild_real_path):\n        if file.endswith(\".wav\"):\n            file_path = os.path.join(wild_real_path, file)\n            if validate_wav_file(file_path):\n                audio_files.append(file_path)\n                labels.append(0)  # Real\n                counts[\"real\"] += 1\n\n    for file in os.listdir(wild_fake_path):\n        if file.endswith(\".wav\"):\n            file_path = os.path.join(wild_fake_path, file)\n            if validate_wav_file(file_path):\n                audio_files.append(file_path)\n                labels.append(1)  # Fake\n                counts[\"fake\"] += 1\n\n    print(f\"In-the-Wild Counts: Real: {counts['real']}, Fake: {counts['fake']}\")\n\n    # Process Fake-or-Real dataset\n    for_counts = {\"fake\": 0, \"real\": 0}\n    for_base_path = DATASET_PATHS[\"fake_or_real\"]\n    for_folders = [\"for-2sec\", \"for-norm\", \"for-original\", \"for-rerec\"]\n    for_subfolders = {\n        \"for-2sec\": \"for-2seconds\",\n        \"for-norm\": \"for-norm\",\n        \"for-original\": \"for-original\",\n        \"for-rerec\": \"for-rerecorded\"\n    }\n    splits = [\"training\", \"validation\", \"testing\"]\n\n    for folder in for_folders:\n        subfolder = for_subfolders[folder]\n        for split in splits:\n            real_path = os.path.join(for_base_path, folder, subfolder, split, \"real\")\n            if os.path.exists(real_path):\n                for file in os.listdir(real_path):\n                    if file.endswith(\".wav\"):\n                        file_path = os.path.join(real_path, file)\n                        if validate_wav_file(file_path):\n                            audio_files.append(file_path)\n                            labels.append(0)  # Real\n                            for_counts[\"real\"] += 1\n\n            fake_path = os.path.join(for_base_path, folder, subfolder, split, \"fake\")\n            if os.path.exists(fake_path):\n                for file in os.listdir(fake_path):\n                    if file.endswith(\".wav\"):\n                        file_path = os.path.join(fake_path, file)\n                        if validate_wav_file(file_path):\n                            audio_files.append(file_path)\n                            labels.append(1)  # Fake\n                            for_counts[\"fake\"] += 1\n\n    print(f\"Fake-or-Real Counts: Real: {for_counts['real']}, Fake: {for_counts['fake']}\")\n    total_counts = {\"real\": counts['real'] + for_counts['real'], \"fake\": counts['fake'] + for_counts['fake']}\n    print(f\"Total Counts: Real: {total_counts['real']}, Fake: {total_counts['fake']}\")\n    return audio_files, labels\n\n# Collect files and labels\nall_files, all_labels = get_audio_files_and_labels()\nprint(f\"\\nTotal files before processing: {len(all_files)}\")\nprint(f\"Label Distribution before processing: Real (0): {sum(1 for label in all_labels if label == 0)} ({sum(1 for label in all_labels if label == 0)/len(all_files)*100:.2f}%), Fake (1): {sum(1 for label in all_labels if label == 1)} ({sum(1 for label in all_labels if label == 1)/len(all_files)*100:.2f}%)\")\n\n# Custom Chroma-STFT implementation using torchaudio\ndef compute_chroma_stft(waveforms, sample_rate=16000, n_fft=2048, hop_length=512, n_chroma=12):\n    # Compute spectrogram\n    spectrogram_transform = Spectrogram(\n        n_fft=n_fft,\n        hop_length=hop_length,\n        power=2.0\n    ).to(device)\n    spec = spectrogram_transform(waveforms)  # (batch, channels, freq, time)\n    \n    # Squeeze the channel dimension (since mono audio)\n    spec = spec.squeeze(1)  # (batch, freq, time)\n    \n    # Create chroma filter bank\n    freqs = torch.linspace(0, sample_rate / 2, steps=spec.shape[1]).to(device)  # Frequency bins\n    chroma_freqs = torch.tensor([31.25 * (2 ** (i / 12)) for i in range(12 * 4)], device=device)  # MIDI 21 to 68 (A0 to C5)\n    chroma_bins = torch.zeros((n_chroma, spec.shape[1]), device=device)\n    \n    for i in range(n_chroma):\n        center = chroma_freqs[i::12]  # All octaves of this note\n        for cf in center:\n            mask = (freqs >= cf / 1.06) & (freqs <= cf * 1.06)  # Approximate triangular filter\n            chroma_bins[i] += mask.float()\n    \n    # Normalize filter bank\n    chroma_bins /= chroma_bins.sum(dim=1, keepdim=True).clamp(min=1e-10)\n    \n    # Apply filter bank to spectrogram\n    chroma = torch.einsum('cf,bft->bct', chroma_bins, spec)  # (batch, n_chroma, time)\n    return chroma\n\n# Feature Extraction\ndef extract_features_batch(file_paths, labels, batch_size=64, max_length=16000):\n    mfcc_results = []\n    lfcc_results = []\n    chroma_results = []\n    valid_labels = []\n    \n    # Define feature extractors\n    mfcc_transform = MFCC(\n        sample_rate=16000,\n        n_mfcc=40,\n        melkwargs={\"n_fft\": 2048, \"hop_length\": 512, \"n_mels\": 128}\n    ).to(device)\n    \n    lfcc_transform = LFCC(\n        sample_rate=16000,\n        n_lfcc=40,\n        f_min=0,\n        f_max=8000,\n        n_filter=128,\n        speckwargs={\"n_fft\": 2048, \"hop_length\": 512}\n    ).to(device)\n    \n    total_batches = (len(file_paths) + batch_size - 1) // batch_size\n    log_interval = max(1, total_batches // 100)  # Logging every 1% progress to check for errors\n    \n    for i in tqdm(range(0, len(file_paths), batch_size), desc=\"Processing Batches\", total=total_batches):\n        if i % (log_interval * batch_size) == 0:\n            print(f\"Processed {i // batch_size}/{total_batches} batches ({(i / len(file_paths)) * 100:.1f}%)\")\n            \n        batch_files = file_paths[i:i + batch_size]\n        batch_labels = labels[i:i + batch_size]\n        waveforms = []\n        valid_indices = []\n        \n        # Load and preprocess waveforms\n        for idx, (file_path, label) in enumerate(zip(batch_files, batch_labels)):\n            try:\n                waveform, sr = torchaudio.load(file_path)\n                # Convert to mono by averaging channels\n                if waveform.shape[0] > 1:\n                    waveform = waveform.mean(dim=0, keepdim=True)  # (channels, samples) -> (1, samples)\n                if sr != 16000:\n                    waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n                \n                if waveform.size(1) > max_length:\n                    waveform = waveform[:, :max_length]\n                elif waveform.size(1) < max_length:\n                    pad_size = max_length - waveform.size(1)\n                    waveform = torch.nn.functional.pad(waveform, (0, pad_size))\n                \n                waveforms.append(waveform)\n                valid_indices.append(idx)\n            except Exception as e:\n                continue\n        \n        if not waveforms:\n            continue\n        \n        try:\n            waveforms = torch.nn.utils.rnn.pad_sequence(waveforms, batch_first=True).to(device)\n            \n            # Extract MFCC\n            mfccs = mfcc_transform(waveforms)  # (batch, n_mfcc, time)\n            \n            # Extract LFCC\n            lfccs = lfcc_transform(waveforms)  # (batch, n_lfcc, time)\n            \n            # Extract Chroma-STFT\n            chromas = compute_chroma_stft(\n                waveforms,\n                sample_rate=16000,\n                n_fft=2048,\n                hop_length=512,\n                n_chroma=12\n            )  # (batch, n_chroma, time)\n            \n            # Standardize time dimension (trim/pad to 32 frames for consistency)\n            target_frames = 32\n            for idx in valid_indices:\n                # MFCC\n                mfcc = mfccs[idx]  # (n_mfcc, time)\n                if mfcc.shape[1] > target_frames:\n                    mfcc = mfcc[:, :target_frames]\n                elif mfcc.shape[1] < target_frames:\n                    mfcc = torch.nn.functional.pad(mfcc, (0, target_frames - mfcc.shape[1]))\n                mfcc_results.append(mfcc.cpu().numpy())\n                \n                # LFCC\n                lfcc = lfccs[idx]  # (n_lfcc, time)\n                if lfcc.shape[1] > target_frames:\n                    lfcc = lfcc[:, :target_frames]\n                elif lfcc.shape[1] < target_frames:\n                    lfcc = torch.nn.functional.pad(lfcc, (0, target_frames - lfcc.shape[1]))\n                lfcc_results.append(lfcc.cpu().numpy())\n                \n                # Chroma-STFT\n                chroma = chromas[idx]  # (n_chroma, time)\n                if chroma.shape[1] > target_frames:\n                    chroma = chroma[:, :target_frames]\n                elif chroma.shape[1] < target_frames:\n                    chroma = torch.nn.functional.pad(chroma, (0, target_frames - chroma.shape[1]))\n                chroma_results.append(chroma.cpu().numpy())\n                \n                valid_labels.append(batch_labels[idx])\n        \n        except Exception as e:\n            print(f\"Error processing batch {i // batch_size}: {e}\")\n            continue\n    \n    return mfcc_results, lfcc_results, chroma_results, valid_labels\n\n# Process files in batches\nmfcc_features, lfcc_features, chroma_features, y = extract_features_batch(all_files, all_labels, batch_size=64, max_length=16000)\n\n# Convert to numpy arrays\nmfcc_features = np.array(mfcc_features)  # (num_samples, n_mfcc, time)\nlfcc_features = np.array(lfcc_features)  # (num_samples, n_lfcc, time)\nchroma_features = np.array(chroma_features)  # (num_samples, n_chroma, time)\ny = np.array(y)\n\n# Validate alignment\nif not (len(mfcc_features) == len(lfcc_features) == len(chroma_features) == len(y)):\n    raise ValueError(f\"Mismatch between features and labels: \"\n                     f\"MFCC: {len(mfcc_features)}, LFCC: {len(lfcc_features)}, \"\n                     f\"Chroma: {len(chroma_features)}, y: {len(y)}\")\n\n# Verify total samples\ntotal_samples = len(y)\nprint(f\"Total samples after feature extraction: {total_samples}\")\nif total_samples != 173128:\n    print(f\"Warning: Expected 173,128 samples, but got {total_samples} samples. Some files may have been skipped due to errors.\")\n\n# Save in chunks (268 chunks of 646 samples each)\nnum_chunks = 268\nchunk_size = total_samples // num_chunks  # Should be 646\ntotal_samples_used = num_chunks * chunk_size\nprint(f\"Total samples: {total_samples}, Number of chunks: {num_chunks}, Chunk size: {chunk_size}\")\nprint(f\"Total samples used: {total_samples_used}\")\n\n# Adjustments if total_samples is not exactly divisible by chunk_size\nif total_samples != total_samples_used:  # Shouldnt be, dont waste data\n    print(f\"Warning: {total_samples - total_samples_used} samples will be dropped due to chunking.\")\n\noutput_dir = \"/kaggle/working/preprocessed_chunks_268\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Clear existing chunks\nfor f in os.listdir(output_dir):\n    os.remove(os.path.join(output_dir, f))\n\n# Save the data in chunks\nfor i in range(0, total_samples_used, chunk_size):\n    chunk_idx = i // chunk_size\n    mfcc_chunk = mfcc_features[i:i + chunk_size]  # (chunk_size, n_mfcc, time)\n    lfcc_chunk = lfcc_features[i:i + chunk_size]  # (chunk_size, n_lfcc, time)\n    chroma_chunk = chroma_features[i:i + chunk_size]  # (chunk_size, n_chroma, time)\n    y_chunk = y[i:i + chunk_size]  # (chunk_size,)\n    \n    if not (len(mfcc_chunk) == len(lfcc_chunk) == len(chroma_chunk) == len(y_chunk)):\n        raise ValueError(f\"Mismatch in chunk {chunk_idx}: \"\n                         f\"MFCC: {len(mfcc_chunk)}, LFCC: {len(lfcc_chunk)}, \"\n                         f\"Chroma: {len(chroma_chunk)}, y: {len(y_chunk)}\")\n    \n    np.save(os.path.join(output_dir, f\"mfcc_chunk_{chunk_idx}.npy\"), mfcc_chunk)\n    np.save(os.path.join(output_dir, f\"lfcc_chunk_{chunk_idx}.npy\"), lfcc_chunk)\n    np.save(os.path.join(output_dir, f\"chroma_chunk_{chunk_idx}.npy\"), chroma_chunk)\n    np.save(os.path.join(output_dir, f\"y_chunk_{chunk_idx}.npy\"), y_chunk)\n    print(f\"Saved chunk {chunk_idx}: \"\n          f\"MFCC shape {mfcc_chunk.shape}, LFCC shape {lfcc_chunk.shape}, \"\n          f\"Chroma shape {chroma_chunk.shape}, y shape {y_chunk.shape}\")\n\nprint(f\"Processed and saved {total_samples_used} audio samples in {output_dir}!\")\n\n# Verify saved files\nprint(\"\\nVerifying all saved files...\")\nchunk_files = [f for f in os.listdir(output_dir) if f.endswith('.npy')]\nprint(f\"Found {len(chunk_files)} .npy files in {output_dir}:\")\nfor chunk_file in sorted(chunk_files):\n    file_path = os.path.join(output_dir, chunk_file)\n    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n    print(f\"{chunk_file}: {size_mb:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T08:19:39.628377Z","iopub.execute_input":"2025-04-24T08:19:39.628646Z","iopub.status.idle":"2025-04-24T09:41:37.608332Z","shell.execute_reply.started":"2025-04-24T08:19:39.628625Z","shell.execute_reply":"2025-04-24T09:41:37.605886Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Using device: cuda, GPU: Tesla T4\nIn-the-Wild Counts: Real: 19963, Fake: 11816\nSkipping invalid file: /kaggle/input/the-fake-or-real-dataset/for-norm/for-norm/training/real/file15440.wav_16k.wav_norm.wav_mono.wav_silence.wav, Error: Failed to decode audio.\nSkipping invalid file: /kaggle/input/the-fake-or-real-dataset/for-norm/for-norm/training/real/file11064.wav_16k.wav_norm.wav_mono.wav_silence.wav, Error: Failed to decode audio.\nFake-or-Real Counts: Real: 84756, Fake: 56593\nTotal Counts: Real: 104719, Fake: 68409\n\nTotal files before processing: 173128\nLabel Distribution before processing: Real (0): 104719 (60.49%), Fake (1): 68409 (39.51%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   0%|          | 0/2706 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 0/2706 batches (0.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   1%|          | 27/2706 [00:07<11:10,  3.99it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 27/2706 batches (1.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   2%|▏         | 54/2706 [00:14<11:37,  3.80it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 54/2706 batches (2.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   3%|▎         | 81/2706 [00:21<10:36,  4.12it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 81/2706 batches (3.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   4%|▍         | 108/2706 [00:27<10:59,  3.94it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 108/2706 batches (4.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   5%|▍         | 135/2706 [00:34<10:30,  4.08it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 135/2706 batches (5.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   6%|▌         | 162/2706 [00:40<10:03,  4.21it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 162/2706 batches (6.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   7%|▋         | 189/2706 [00:53<27:16,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 189/2706 batches (7.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   8%|▊         | 216/2706 [01:11<29:06,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 216/2706 batches (8.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:   9%|▉         | 243/2706 [01:30<28:22,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 243/2706 batches (9.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  10%|▉         | 270/2706 [01:47<25:11,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 270/2706 batches (10.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  11%|█         | 297/2706 [02:03<24:59,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 297/2706 batches (11.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  12%|█▏        | 324/2706 [02:21<27:13,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 324/2706 batches (12.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  13%|█▎        | 351/2706 [02:40<28:19,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 351/2706 batches (13.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  14%|█▍        | 378/2706 [02:58<26:18,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 378/2706 batches (14.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  15%|█▍        | 405/2706 [03:17<28:02,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 405/2706 batches (15.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  16%|█▌        | 432/2706 [03:36<25:57,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 432/2706 batches (16.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  17%|█▋        | 459/2706 [03:55<24:57,  1.50it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 459/2706 batches (17.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  18%|█▊        | 486/2706 [04:13<26:27,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 486/2706 batches (18.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  19%|█▉        | 513/2706 [04:29<18:01,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 513/2706 batches (19.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  20%|█▉        | 540/2706 [04:43<17:54,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 540/2706 batches (20.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  21%|██        | 567/2706 [04:56<17:34,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 567/2706 batches (21.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  22%|██▏       | 594/2706 [05:10<18:13,  1.93it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 594/2706 batches (22.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  23%|██▎       | 621/2706 [05:23<17:14,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 621/2706 batches (23.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  24%|██▍       | 648/2706 [05:37<16:59,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 648/2706 batches (24.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  25%|██▍       | 675/2706 [05:51<17:44,  1.91it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 675/2706 batches (25.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  26%|██▌       | 702/2706 [06:05<18:45,  1.78it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 702/2706 batches (26.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  27%|██▋       | 729/2706 [06:20<17:29,  1.88it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 729/2706 batches (26.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  28%|██▊       | 756/2706 [06:34<17:45,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 756/2706 batches (27.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  29%|██▉       | 783/2706 [06:50<27:44,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 783/2706 batches (28.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  30%|██▉       | 810/2706 [07:16<29:47,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 810/2706 batches (29.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  31%|███       | 837/2706 [07:41<29:23,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 837/2706 batches (30.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  32%|███▏      | 864/2706 [08:07<29:19,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 864/2706 batches (31.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  33%|███▎      | 891/2706 [08:32<28:27,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 891/2706 batches (32.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  34%|███▍      | 918/2706 [08:57<27:32,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 918/2706 batches (33.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  35%|███▍      | 945/2706 [09:23<27:40,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 945/2706 batches (34.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  36%|███▌      | 972/2706 [09:48<26:58,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 972/2706 batches (35.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  37%|███▋      | 999/2706 [10:13<27:07,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 999/2706 batches (36.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  38%|███▊      | 1026/2706 [10:38<25:19,  1.11it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1026/2706 batches (37.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  39%|███▉      | 1053/2706 [11:03<25:34,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1053/2706 batches (38.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  40%|███▉      | 1080/2706 [11:28<24:40,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1080/2706 batches (39.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  41%|████      | 1107/2706 [11:53<24:15,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1107/2706 batches (40.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  42%|████▏     | 1134/2706 [12:17<23:26,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1134/2706 batches (41.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  43%|████▎     | 1161/2706 [12:42<23:07,  1.11it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1161/2706 batches (42.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  44%|████▍     | 1188/2706 [13:07<24:02,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1188/2706 batches (43.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  45%|████▍     | 1215/2706 [13:25<14:43,  1.69it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1215/2706 batches (44.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  46%|████▌     | 1242/2706 [13:40<13:33,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1242/2706 batches (45.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  47%|████▋     | 1269/2706 [13:55<13:05,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1269/2706 batches (46.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  48%|████▊     | 1296/2706 [14:10<13:05,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1296/2706 batches (47.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  49%|████▉     | 1323/2706 [14:25<13:46,  1.67it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1323/2706 batches (48.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  50%|████▉     | 1350/2706 [14:40<12:23,  1.82it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1350/2706 batches (49.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  51%|█████     | 1377/2706 [14:55<12:29,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1377/2706 batches (50.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  52%|█████▏    | 1404/2706 [15:11<11:41,  1.86it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1404/2706 batches (51.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  53%|█████▎    | 1431/2706 [15:26<12:03,  1.76it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1431/2706 batches (52.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  54%|█████▍    | 1458/2706 [15:41<11:11,  1.86it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1458/2706 batches (53.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  55%|█████▍    | 1485/2706 [15:56<11:38,  1.75it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1485/2706 batches (54.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  56%|█████▌    | 1512/2706 [16:12<11:32,  1.72it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1512/2706 batches (55.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  57%|█████▋    | 1539/2706 [16:28<11:33,  1.68it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1539/2706 batches (56.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  58%|█████▊    | 1566/2706 [16:44<10:23,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1566/2706 batches (57.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  59%|█████▉    | 1593/2706 [16:59<10:46,  1.72it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1593/2706 batches (58.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  60%|█████▉    | 1620/2706 [17:16<14:31,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1620/2706 batches (59.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  61%|██████    | 1647/2706 [17:42<16:50,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1647/2706 batches (60.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  62%|██████▏   | 1674/2706 [18:08<17:23,  1.01s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1674/2706 batches (61.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  63%|██████▎   | 1701/2706 [18:33<15:51,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1701/2706 batches (62.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  64%|██████▍   | 1728/2706 [18:48<08:49,  1.85it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1728/2706 batches (63.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  65%|██████▍   | 1755/2706 [19:03<09:09,  1.73it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1755/2706 batches (64.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  66%|██████▌   | 1782/2706 [19:19<08:33,  1.80it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1782/2706 batches (65.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  67%|██████▋   | 1809/2706 [19:38<11:20,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1809/2706 batches (66.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  68%|██████▊   | 1836/2706 [19:55<07:46,  1.86it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 1836/2706 batches (67.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  69%|██████▉   | 1863/2706 [20:14<17:40,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1863/2706 batches (68.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  70%|██████▉   | 1890/2706 [20:49<17:23,  1.28s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1890/2706 batches (69.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  71%|███████   | 1917/2706 [21:23<16:56,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1917/2706 batches (70.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  72%|███████▏  | 1944/2706 [21:57<15:42,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1944/2706 batches (71.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  73%|███████▎  | 1971/2706 [22:32<16:20,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1971/2706 batches (72.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  74%|███████▍  | 1998/2706 [23:07<15:30,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1998/2706 batches (73.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  75%|███████▍  | 2025/2706 [23:42<14:13,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2025/2706 batches (74.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  76%|███████▌  | 2052/2706 [24:17<14:00,  1.29s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2052/2706 batches (75.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  77%|███████▋  | 2079/2706 [24:52<13:15,  1.27s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2079/2706 batches (76.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  78%|███████▊  | 2106/2706 [25:27<12:36,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2106/2706 batches (77.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  79%|███████▉  | 2133/2706 [26:01<12:26,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2133/2706 batches (78.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  80%|███████▉  | 2160/2706 [26:37<12:38,  1.39s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2160/2706 batches (79.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  81%|████████  | 2187/2706 [27:13<11:54,  1.38s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2187/2706 batches (80.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  82%|████████▏ | 2214/2706 [27:48<10:41,  1.30s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2214/2706 batches (81.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  83%|████████▎ | 2241/2706 [28:26<11:36,  1.50s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2241/2706 batches (82.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  84%|████████▍ | 2268/2706 [29:04<10:36,  1.45s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2268/2706 batches (83.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  85%|████████▍ | 2295/2706 [29:36<06:37,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2295/2706 batches (84.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  86%|████████▌ | 2322/2706 [30:02<06:07,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2322/2706 batches (85.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  87%|████████▋ | 2349/2706 [30:35<07:58,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2349/2706 batches (86.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  88%|████████▊ | 2376/2706 [31:11<07:42,  1.40s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2376/2706 batches (87.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  89%|████████▉ | 2403/2706 [31:46<06:19,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2403/2706 batches (88.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  90%|████████▉ | 2430/2706 [32:15<03:57,  1.16it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2430/2706 batches (89.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  91%|█████████ | 2457/2706 [32:38<03:24,  1.21it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2457/2706 batches (90.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  92%|█████████▏| 2484/2706 [33:03<03:33,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2484/2706 batches (91.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  93%|█████████▎| 2511/2706 [33:23<01:22,  2.36it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2511/2706 batches (92.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  94%|█████████▍| 2538/2706 [33:34<01:12,  2.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2538/2706 batches (93.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  95%|█████████▍| 2565/2706 [33:46<00:57,  2.44it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2565/2706 batches (94.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  96%|█████████▌| 2592/2706 [33:57<00:46,  2.45it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2592/2706 batches (95.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  97%|█████████▋| 2619/2706 [34:11<00:48,  1.79it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2619/2706 batches (96.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  98%|█████████▊| 2646/2706 [34:27<00:33,  1.77it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2646/2706 batches (97.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches:  99%|█████████▉| 2673/2706 [34:42<00:18,  1.75it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2673/2706 batches (98.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches: 100%|█████████▉| 2700/2706 [34:58<00:03,  1.73it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2700/2706 batches (99.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing Batches: 100%|██████████| 2706/2706 [35:01<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Total samples after feature extraction: 173128\nTotal samples: 173128, Number of chunks: 268, Chunk size: 646\nTotal samples used: 173128\nSaved chunk 0: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 1: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 2: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 3: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 4: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 5: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 6: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 7: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 8: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 9: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 10: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 11: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 12: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 13: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 14: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 15: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 16: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 17: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 18: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 19: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 20: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 21: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 22: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 23: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 24: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 25: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 26: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 27: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 28: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 29: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 30: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 31: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 32: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 33: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 34: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 35: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 36: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 37: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 38: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 39: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 40: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 41: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 42: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 43: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 44: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 45: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 46: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 47: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 48: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 49: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 50: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 51: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 52: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 53: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 54: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 55: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 56: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 57: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 58: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 59: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 60: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 61: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 62: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 63: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 64: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 65: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 66: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 67: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 68: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 69: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 70: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 71: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 72: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 73: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 74: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 75: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 76: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 77: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 78: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 79: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 80: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 81: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 82: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 83: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 84: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 85: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 86: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 87: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 88: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 89: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 90: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 91: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 92: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 93: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 94: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 95: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 96: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 97: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 98: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 99: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 100: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 101: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 102: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 103: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 104: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 105: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 106: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 107: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 108: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 109: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 110: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 111: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 112: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 113: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 114: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 115: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 116: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 117: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 118: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 119: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 120: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 121: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 122: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 123: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 124: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 125: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 126: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 127: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 128: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 129: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 130: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 131: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 132: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 133: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 134: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 135: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 136: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 137: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 138: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 139: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 140: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 141: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 142: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 143: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 144: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 145: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 146: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 147: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 148: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 149: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 150: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 151: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 152: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 153: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 154: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 155: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 156: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 157: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 158: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 159: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 160: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 161: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 162: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 163: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 164: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 165: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 166: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 167: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 168: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 169: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 170: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 171: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 172: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 173: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 174: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 175: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 176: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 177: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 178: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 179: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 180: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 181: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 182: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 183: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 184: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 185: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 186: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 187: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 188: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 189: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 190: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 191: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 192: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 193: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 194: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 195: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 196: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 197: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 198: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 199: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 200: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 201: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 202: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 203: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 204: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 205: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 206: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 207: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 208: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 209: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 210: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 211: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 212: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 213: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 214: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 215: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 216: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 217: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 218: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 219: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 220: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 221: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 222: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 223: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 224: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 225: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 226: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 227: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 228: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 229: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 230: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 231: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 232: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 233: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 234: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 235: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 236: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 237: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 238: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 239: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 240: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 241: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 242: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 243: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 244: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 245: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 246: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 247: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 248: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 249: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 250: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 251: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 252: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 253: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 254: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 255: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 256: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 257: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 258: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 259: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 260: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 261: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 262: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 263: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 264: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 265: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 266: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nSaved chunk 267: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 12, 32), y shape (646,)\nProcessed and saved 173128 audio samples in /kaggle/working/preprocessed_chunks_268!\n\nVerifying all saved files...\nFound 1072 .npy files in /kaggle/working/preprocessed_chunks_268:\nchroma_chunk_0.npy: 0.95 MB\nchroma_chunk_1.npy: 0.95 MB\nchroma_chunk_10.npy: 0.95 MB\nchroma_chunk_100.npy: 0.95 MB\nchroma_chunk_101.npy: 0.95 MB\nchroma_chunk_102.npy: 0.95 MB\nchroma_chunk_103.npy: 0.95 MB\nchroma_chunk_104.npy: 0.95 MB\nchroma_chunk_105.npy: 0.95 MB\nchroma_chunk_106.npy: 0.95 MB\nchroma_chunk_107.npy: 0.95 MB\nchroma_chunk_108.npy: 0.95 MB\nchroma_chunk_109.npy: 0.95 MB\nchroma_chunk_11.npy: 0.95 MB\nchroma_chunk_110.npy: 0.95 MB\nchroma_chunk_111.npy: 0.95 MB\nchroma_chunk_112.npy: 0.95 MB\nchroma_chunk_113.npy: 0.95 MB\nchroma_chunk_114.npy: 0.95 MB\nchroma_chunk_115.npy: 0.95 MB\nchroma_chunk_116.npy: 0.95 MB\nchroma_chunk_117.npy: 0.95 MB\nchroma_chunk_118.npy: 0.95 MB\nchroma_chunk_119.npy: 0.95 MB\nchroma_chunk_12.npy: 0.95 MB\nchroma_chunk_120.npy: 0.95 MB\nchroma_chunk_121.npy: 0.95 MB\nchroma_chunk_122.npy: 0.95 MB\nchroma_chunk_123.npy: 0.95 MB\nchroma_chunk_124.npy: 0.95 MB\nchroma_chunk_125.npy: 0.95 MB\nchroma_chunk_126.npy: 0.95 MB\nchroma_chunk_127.npy: 0.95 MB\nchroma_chunk_128.npy: 0.95 MB\nchroma_chunk_129.npy: 0.95 MB\nchroma_chunk_13.npy: 0.95 MB\nchroma_chunk_130.npy: 0.95 MB\nchroma_chunk_131.npy: 0.95 MB\nchroma_chunk_132.npy: 0.95 MB\nchroma_chunk_133.npy: 0.95 MB\nchroma_chunk_134.npy: 0.95 MB\nchroma_chunk_135.npy: 0.95 MB\nchroma_chunk_136.npy: 0.95 MB\nchroma_chunk_137.npy: 0.95 MB\nchroma_chunk_138.npy: 0.95 MB\nchroma_chunk_139.npy: 0.95 MB\nchroma_chunk_14.npy: 0.95 MB\nchroma_chunk_140.npy: 0.95 MB\nchroma_chunk_141.npy: 0.95 MB\nchroma_chunk_142.npy: 0.95 MB\nchroma_chunk_143.npy: 0.95 MB\nchroma_chunk_144.npy: 0.95 MB\nchroma_chunk_145.npy: 0.95 MB\nchroma_chunk_146.npy: 0.95 MB\nchroma_chunk_147.npy: 0.95 MB\nchroma_chunk_148.npy: 0.95 MB\nchroma_chunk_149.npy: 0.95 MB\nchroma_chunk_15.npy: 0.95 MB\nchroma_chunk_150.npy: 0.95 MB\nchroma_chunk_151.npy: 0.95 MB\nchroma_chunk_152.npy: 0.95 MB\nchroma_chunk_153.npy: 0.95 MB\nchroma_chunk_154.npy: 0.95 MB\nchroma_chunk_155.npy: 0.95 MB\nchroma_chunk_156.npy: 0.95 MB\nchroma_chunk_157.npy: 0.95 MB\nchroma_chunk_158.npy: 0.95 MB\nchroma_chunk_159.npy: 0.95 MB\nchroma_chunk_16.npy: 0.95 MB\nchroma_chunk_160.npy: 0.95 MB\nchroma_chunk_161.npy: 0.95 MB\nchroma_chunk_162.npy: 0.95 MB\nchroma_chunk_163.npy: 0.95 MB\nchroma_chunk_164.npy: 0.95 MB\nchroma_chunk_165.npy: 0.95 MB\nchroma_chunk_166.npy: 0.95 MB\nchroma_chunk_167.npy: 0.95 MB\nchroma_chunk_168.npy: 0.95 MB\nchroma_chunk_169.npy: 0.95 MB\nchroma_chunk_17.npy: 0.95 MB\nchroma_chunk_170.npy: 0.95 MB\nchroma_chunk_171.npy: 0.95 MB\nchroma_chunk_172.npy: 0.95 MB\nchroma_chunk_173.npy: 0.95 MB\nchroma_chunk_174.npy: 0.95 MB\nchroma_chunk_175.npy: 0.95 MB\nchroma_chunk_176.npy: 0.95 MB\nchroma_chunk_177.npy: 0.95 MB\nchroma_chunk_178.npy: 0.95 MB\nchroma_chunk_179.npy: 0.95 MB\nchroma_chunk_18.npy: 0.95 MB\nchroma_chunk_180.npy: 0.95 MB\nchroma_chunk_181.npy: 0.95 MB\nchroma_chunk_182.npy: 0.95 MB\nchroma_chunk_183.npy: 0.95 MB\nchroma_chunk_184.npy: 0.95 MB\nchroma_chunk_185.npy: 0.95 MB\nchroma_chunk_186.npy: 0.95 MB\nchroma_chunk_187.npy: 0.95 MB\nchroma_chunk_188.npy: 0.95 MB\nchroma_chunk_189.npy: 0.95 MB\nchroma_chunk_19.npy: 0.95 MB\nchroma_chunk_190.npy: 0.95 MB\nchroma_chunk_191.npy: 0.95 MB\nchroma_chunk_192.npy: 0.95 MB\nchroma_chunk_193.npy: 0.95 MB\nchroma_chunk_194.npy: 0.95 MB\nchroma_chunk_195.npy: 0.95 MB\nchroma_chunk_196.npy: 0.95 MB\nchroma_chunk_197.npy: 0.95 MB\nchroma_chunk_198.npy: 0.95 MB\nchroma_chunk_199.npy: 0.95 MB\nchroma_chunk_2.npy: 0.95 MB\nchroma_chunk_20.npy: 0.95 MB\nchroma_chunk_200.npy: 0.95 MB\nchroma_chunk_201.npy: 0.95 MB\nchroma_chunk_202.npy: 0.95 MB\nchroma_chunk_203.npy: 0.95 MB\nchroma_chunk_204.npy: 0.95 MB\nchroma_chunk_205.npy: 0.95 MB\nchroma_chunk_206.npy: 0.95 MB\nchroma_chunk_207.npy: 0.95 MB\nchroma_chunk_208.npy: 0.95 MB\nchroma_chunk_209.npy: 0.95 MB\nchroma_chunk_21.npy: 0.95 MB\nchroma_chunk_210.npy: 0.95 MB\nchroma_chunk_211.npy: 0.95 MB\nchroma_chunk_212.npy: 0.95 MB\nchroma_chunk_213.npy: 0.95 MB\nchroma_chunk_214.npy: 0.95 MB\nchroma_chunk_215.npy: 0.95 MB\nchroma_chunk_216.npy: 0.95 MB\nchroma_chunk_217.npy: 0.95 MB\nchroma_chunk_218.npy: 0.95 MB\nchroma_chunk_219.npy: 0.95 MB\nchroma_chunk_22.npy: 0.95 MB\nchroma_chunk_220.npy: 0.95 MB\nchroma_chunk_221.npy: 0.95 MB\nchroma_chunk_222.npy: 0.95 MB\nchroma_chunk_223.npy: 0.95 MB\nchroma_chunk_224.npy: 0.95 MB\nchroma_chunk_225.npy: 0.95 MB\nchroma_chunk_226.npy: 0.95 MB\nchroma_chunk_227.npy: 0.95 MB\nchroma_chunk_228.npy: 0.95 MB\nchroma_chunk_229.npy: 0.95 MB\nchroma_chunk_23.npy: 0.95 MB\nchroma_chunk_230.npy: 0.95 MB\nchroma_chunk_231.npy: 0.95 MB\nchroma_chunk_232.npy: 0.95 MB\nchroma_chunk_233.npy: 0.95 MB\nchroma_chunk_234.npy: 0.95 MB\nchroma_chunk_235.npy: 0.95 MB\nchroma_chunk_236.npy: 0.95 MB\nchroma_chunk_237.npy: 0.95 MB\nchroma_chunk_238.npy: 0.95 MB\nchroma_chunk_239.npy: 0.95 MB\nchroma_chunk_24.npy: 0.95 MB\nchroma_chunk_240.npy: 0.95 MB\nchroma_chunk_241.npy: 0.95 MB\nchroma_chunk_242.npy: 0.95 MB\nchroma_chunk_243.npy: 0.95 MB\nchroma_chunk_244.npy: 0.95 MB\nchroma_chunk_245.npy: 0.95 MB\nchroma_chunk_246.npy: 0.95 MB\nchroma_chunk_247.npy: 0.95 MB\nchroma_chunk_248.npy: 0.95 MB\nchroma_chunk_249.npy: 0.95 MB\nchroma_chunk_25.npy: 0.95 MB\nchroma_chunk_250.npy: 0.95 MB\nchroma_chunk_251.npy: 0.95 MB\nchroma_chunk_252.npy: 0.95 MB\nchroma_chunk_253.npy: 0.95 MB\nchroma_chunk_254.npy: 0.95 MB\nchroma_chunk_255.npy: 0.95 MB\nchroma_chunk_256.npy: 0.95 MB\nchroma_chunk_257.npy: 0.95 MB\nchroma_chunk_258.npy: 0.95 MB\nchroma_chunk_259.npy: 0.95 MB\nchroma_chunk_26.npy: 0.95 MB\nchroma_chunk_260.npy: 0.95 MB\nchroma_chunk_261.npy: 0.95 MB\nchroma_chunk_262.npy: 0.95 MB\nchroma_chunk_263.npy: 0.95 MB\nchroma_chunk_264.npy: 0.95 MB\nchroma_chunk_265.npy: 0.95 MB\nchroma_chunk_266.npy: 0.95 MB\nchroma_chunk_267.npy: 0.95 MB\nchroma_chunk_27.npy: 0.95 MB\nchroma_chunk_28.npy: 0.95 MB\nchroma_chunk_29.npy: 0.95 MB\nchroma_chunk_3.npy: 0.95 MB\nchroma_chunk_30.npy: 0.95 MB\nchroma_chunk_31.npy: 0.95 MB\nchroma_chunk_32.npy: 0.95 MB\nchroma_chunk_33.npy: 0.95 MB\nchroma_chunk_34.npy: 0.95 MB\nchroma_chunk_35.npy: 0.95 MB\nchroma_chunk_36.npy: 0.95 MB\nchroma_chunk_37.npy: 0.95 MB\nchroma_chunk_38.npy: 0.95 MB\nchroma_chunk_39.npy: 0.95 MB\nchroma_chunk_4.npy: 0.95 MB\nchroma_chunk_40.npy: 0.95 MB\nchroma_chunk_41.npy: 0.95 MB\nchroma_chunk_42.npy: 0.95 MB\nchroma_chunk_43.npy: 0.95 MB\nchroma_chunk_44.npy: 0.95 MB\nchroma_chunk_45.npy: 0.95 MB\nchroma_chunk_46.npy: 0.95 MB\nchroma_chunk_47.npy: 0.95 MB\nchroma_chunk_48.npy: 0.95 MB\nchroma_chunk_49.npy: 0.95 MB\nchroma_chunk_5.npy: 0.95 MB\nchroma_chunk_50.npy: 0.95 MB\nchroma_chunk_51.npy: 0.95 MB\nchroma_chunk_52.npy: 0.95 MB\nchroma_chunk_53.npy: 0.95 MB\nchroma_chunk_54.npy: 0.95 MB\nchroma_chunk_55.npy: 0.95 MB\nchroma_chunk_56.npy: 0.95 MB\nchroma_chunk_57.npy: 0.95 MB\nchroma_chunk_58.npy: 0.95 MB\nchroma_chunk_59.npy: 0.95 MB\nchroma_chunk_6.npy: 0.95 MB\nchroma_chunk_60.npy: 0.95 MB\nchroma_chunk_61.npy: 0.95 MB\nchroma_chunk_62.npy: 0.95 MB\nchroma_chunk_63.npy: 0.95 MB\nchroma_chunk_64.npy: 0.95 MB\nchroma_chunk_65.npy: 0.95 MB\nchroma_chunk_66.npy: 0.95 MB\nchroma_chunk_67.npy: 0.95 MB\nchroma_chunk_68.npy: 0.95 MB\nchroma_chunk_69.npy: 0.95 MB\nchroma_chunk_7.npy: 0.95 MB\nchroma_chunk_70.npy: 0.95 MB\nchroma_chunk_71.npy: 0.95 MB\nchroma_chunk_72.npy: 0.95 MB\nchroma_chunk_73.npy: 0.95 MB\nchroma_chunk_74.npy: 0.95 MB\nchroma_chunk_75.npy: 0.95 MB\nchroma_chunk_76.npy: 0.95 MB\nchroma_chunk_77.npy: 0.95 MB\nchroma_chunk_78.npy: 0.95 MB\nchroma_chunk_79.npy: 0.95 MB\nchroma_chunk_8.npy: 0.95 MB\nchroma_chunk_80.npy: 0.95 MB\nchroma_chunk_81.npy: 0.95 MB\nchroma_chunk_82.npy: 0.95 MB\nchroma_chunk_83.npy: 0.95 MB\nchroma_chunk_84.npy: 0.95 MB\nchroma_chunk_85.npy: 0.95 MB\nchroma_chunk_86.npy: 0.95 MB\nchroma_chunk_87.npy: 0.95 MB\nchroma_chunk_88.npy: 0.95 MB\nchroma_chunk_89.npy: 0.95 MB\nchroma_chunk_9.npy: 0.95 MB\nchroma_chunk_90.npy: 0.95 MB\nchroma_chunk_91.npy: 0.95 MB\nchroma_chunk_92.npy: 0.95 MB\nchroma_chunk_93.npy: 0.95 MB\nchroma_chunk_94.npy: 0.95 MB\nchroma_chunk_95.npy: 0.95 MB\nchroma_chunk_96.npy: 0.95 MB\nchroma_chunk_97.npy: 0.95 MB\nchroma_chunk_98.npy: 0.95 MB\nchroma_chunk_99.npy: 0.95 MB\nlfcc_chunk_0.npy: 2.52 MB\nlfcc_chunk_1.npy: 2.52 MB\nlfcc_chunk_10.npy: 2.52 MB\nlfcc_chunk_100.npy: 2.52 MB\nlfcc_chunk_101.npy: 2.52 MB\nlfcc_chunk_102.npy: 2.52 MB\nlfcc_chunk_103.npy: 2.52 MB\nlfcc_chunk_104.npy: 2.52 MB\nlfcc_chunk_105.npy: 2.52 MB\nlfcc_chunk_106.npy: 2.52 MB\nlfcc_chunk_107.npy: 2.52 MB\nlfcc_chunk_108.npy: 2.52 MB\nlfcc_chunk_109.npy: 2.52 MB\nlfcc_chunk_11.npy: 2.52 MB\nlfcc_chunk_110.npy: 2.52 MB\nlfcc_chunk_111.npy: 2.52 MB\nlfcc_chunk_112.npy: 2.52 MB\nlfcc_chunk_113.npy: 2.52 MB\nlfcc_chunk_114.npy: 2.52 MB\nlfcc_chunk_115.npy: 2.52 MB\nlfcc_chunk_116.npy: 2.52 MB\nlfcc_chunk_117.npy: 2.52 MB\nlfcc_chunk_118.npy: 2.52 MB\nlfcc_chunk_119.npy: 2.52 MB\nlfcc_chunk_12.npy: 2.52 MB\nlfcc_chunk_120.npy: 2.52 MB\nlfcc_chunk_121.npy: 2.52 MB\nlfcc_chunk_122.npy: 2.52 MB\nlfcc_chunk_123.npy: 2.52 MB\nlfcc_chunk_124.npy: 2.52 MB\nlfcc_chunk_125.npy: 2.52 MB\nlfcc_chunk_126.npy: 2.52 MB\nlfcc_chunk_127.npy: 2.52 MB\nlfcc_chunk_128.npy: 2.52 MB\nlfcc_chunk_129.npy: 2.52 MB\nlfcc_chunk_13.npy: 2.52 MB\nlfcc_chunk_130.npy: 2.52 MB\nlfcc_chunk_131.npy: 2.52 MB\nlfcc_chunk_132.npy: 2.52 MB\nlfcc_chunk_133.npy: 2.52 MB\nlfcc_chunk_134.npy: 2.52 MB\nlfcc_chunk_135.npy: 2.52 MB\nlfcc_chunk_136.npy: 2.52 MB\nlfcc_chunk_137.npy: 2.52 MB\nlfcc_chunk_138.npy: 2.52 MB\nlfcc_chunk_139.npy: 2.52 MB\nlfcc_chunk_14.npy: 2.52 MB\nlfcc_chunk_140.npy: 2.52 MB\nlfcc_chunk_141.npy: 2.52 MB\nlfcc_chunk_142.npy: 2.52 MB\nlfcc_chunk_143.npy: 2.52 MB\nlfcc_chunk_144.npy: 2.52 MB\nlfcc_chunk_145.npy: 2.52 MB\nlfcc_chunk_146.npy: 2.52 MB\nlfcc_chunk_147.npy: 2.52 MB\nlfcc_chunk_148.npy: 2.52 MB\nlfcc_chunk_149.npy: 2.52 MB\nlfcc_chunk_15.npy: 2.52 MB\nlfcc_chunk_150.npy: 2.52 MB\nlfcc_chunk_151.npy: 2.52 MB\nlfcc_chunk_152.npy: 2.52 MB\nlfcc_chunk_153.npy: 2.52 MB\nlfcc_chunk_154.npy: 2.52 MB\nlfcc_chunk_155.npy: 2.52 MB\nlfcc_chunk_156.npy: 2.52 MB\nlfcc_chunk_157.npy: 2.52 MB\nlfcc_chunk_158.npy: 2.52 MB\nlfcc_chunk_159.npy: 2.52 MB\nlfcc_chunk_16.npy: 2.52 MB\nlfcc_chunk_160.npy: 2.52 MB\nlfcc_chunk_161.npy: 2.52 MB\nlfcc_chunk_162.npy: 2.52 MB\nlfcc_chunk_163.npy: 2.52 MB\nlfcc_chunk_164.npy: 2.52 MB\nlfcc_chunk_165.npy: 2.52 MB\nlfcc_chunk_166.npy: 2.52 MB\nlfcc_chunk_167.npy: 2.52 MB\nlfcc_chunk_168.npy: 2.52 MB\nlfcc_chunk_169.npy: 2.52 MB\nlfcc_chunk_17.npy: 2.52 MB\nlfcc_chunk_170.npy: 2.52 MB\nlfcc_chunk_171.npy: 2.52 MB\nlfcc_chunk_172.npy: 2.52 MB\nlfcc_chunk_173.npy: 2.52 MB\nlfcc_chunk_174.npy: 2.52 MB\nlfcc_chunk_175.npy: 2.52 MB\nlfcc_chunk_176.npy: 2.52 MB\nlfcc_chunk_177.npy: 2.52 MB\nlfcc_chunk_178.npy: 2.52 MB\nlfcc_chunk_179.npy: 2.52 MB\nlfcc_chunk_18.npy: 2.52 MB\nlfcc_chunk_180.npy: 2.52 MB\nlfcc_chunk_181.npy: 2.52 MB\nlfcc_chunk_182.npy: 2.52 MB\nlfcc_chunk_183.npy: 2.52 MB\nlfcc_chunk_184.npy: 2.52 MB\nlfcc_chunk_185.npy: 2.52 MB\nlfcc_chunk_186.npy: 2.52 MB\nlfcc_chunk_187.npy: 2.52 MB\nlfcc_chunk_188.npy: 2.52 MB\nlfcc_chunk_189.npy: 2.52 MB\nlfcc_chunk_19.npy: 2.52 MB\nlfcc_chunk_190.npy: 2.52 MB\nlfcc_chunk_191.npy: 2.52 MB\nlfcc_chunk_192.npy: 2.52 MB\nlfcc_chunk_193.npy: 2.52 MB\nlfcc_chunk_194.npy: 2.52 MB\nlfcc_chunk_195.npy: 2.52 MB\nlfcc_chunk_196.npy: 2.52 MB\nlfcc_chunk_197.npy: 2.52 MB\nlfcc_chunk_198.npy: 2.52 MB\nlfcc_chunk_199.npy: 2.52 MB\nlfcc_chunk_2.npy: 2.52 MB\nlfcc_chunk_20.npy: 2.52 MB\nlfcc_chunk_200.npy: 2.52 MB\nlfcc_chunk_201.npy: 2.52 MB\nlfcc_chunk_202.npy: 2.52 MB\nlfcc_chunk_203.npy: 2.52 MB\nlfcc_chunk_204.npy: 2.52 MB\nlfcc_chunk_205.npy: 2.52 MB\nlfcc_chunk_206.npy: 2.52 MB\nlfcc_chunk_207.npy: 2.52 MB\nlfcc_chunk_208.npy: 2.52 MB\nlfcc_chunk_209.npy: 2.52 MB\nlfcc_chunk_21.npy: 2.52 MB\nlfcc_chunk_210.npy: 2.52 MB\nlfcc_chunk_211.npy: 2.52 MB\nlfcc_chunk_212.npy: 2.52 MB\nlfcc_chunk_213.npy: 2.52 MB\nlfcc_chunk_214.npy: 2.52 MB\nlfcc_chunk_215.npy: 2.52 MB\nlfcc_chunk_216.npy: 2.52 MB\nlfcc_chunk_217.npy: 2.52 MB\nlfcc_chunk_218.npy: 2.52 MB\nlfcc_chunk_219.npy: 2.52 MB\nlfcc_chunk_22.npy: 2.52 MB\nlfcc_chunk_220.npy: 2.52 MB\nlfcc_chunk_221.npy: 2.52 MB\nlfcc_chunk_222.npy: 2.52 MB\nlfcc_chunk_223.npy: 2.52 MB\nlfcc_chunk_224.npy: 2.52 MB\nlfcc_chunk_225.npy: 2.52 MB\nlfcc_chunk_226.npy: 2.52 MB\nlfcc_chunk_227.npy: 2.52 MB\nlfcc_chunk_228.npy: 2.52 MB\nlfcc_chunk_229.npy: 2.52 MB\nlfcc_chunk_23.npy: 2.52 MB\nlfcc_chunk_230.npy: 2.52 MB\nlfcc_chunk_231.npy: 2.52 MB\nlfcc_chunk_232.npy: 2.52 MB\nlfcc_chunk_233.npy: 2.52 MB\nlfcc_chunk_234.npy: 2.52 MB\nlfcc_chunk_235.npy: 2.52 MB\nlfcc_chunk_236.npy: 2.52 MB\nlfcc_chunk_237.npy: 2.52 MB\nlfcc_chunk_238.npy: 2.52 MB\nlfcc_chunk_239.npy: 2.52 MB\nlfcc_chunk_24.npy: 2.52 MB\nlfcc_chunk_240.npy: 2.52 MB\nlfcc_chunk_241.npy: 2.52 MB\nlfcc_chunk_242.npy: 2.52 MB\nlfcc_chunk_243.npy: 2.52 MB\nlfcc_chunk_244.npy: 2.52 MB\nlfcc_chunk_245.npy: 2.52 MB\nlfcc_chunk_246.npy: 2.52 MB\nlfcc_chunk_247.npy: 2.52 MB\nlfcc_chunk_248.npy: 2.52 MB\nlfcc_chunk_249.npy: 2.52 MB\nlfcc_chunk_25.npy: 2.52 MB\nlfcc_chunk_250.npy: 2.52 MB\nlfcc_chunk_251.npy: 2.52 MB\nlfcc_chunk_252.npy: 2.52 MB\nlfcc_chunk_253.npy: 2.52 MB\nlfcc_chunk_254.npy: 2.52 MB\nlfcc_chunk_255.npy: 2.52 MB\nlfcc_chunk_256.npy: 2.52 MB\nlfcc_chunk_257.npy: 2.52 MB\nlfcc_chunk_258.npy: 2.52 MB\nlfcc_chunk_259.npy: 2.52 MB\nlfcc_chunk_26.npy: 2.52 MB\nlfcc_chunk_260.npy: 2.52 MB\nlfcc_chunk_261.npy: 2.52 MB\nlfcc_chunk_262.npy: 2.52 MB\nlfcc_chunk_263.npy: 2.52 MB\nlfcc_chunk_264.npy: 2.52 MB\nlfcc_chunk_265.npy: 2.52 MB\nlfcc_chunk_266.npy: 2.52 MB\nlfcc_chunk_267.npy: 2.52 MB\nlfcc_chunk_27.npy: 2.52 MB\nlfcc_chunk_28.npy: 2.52 MB\nlfcc_chunk_29.npy: 2.52 MB\nlfcc_chunk_3.npy: 2.52 MB\nlfcc_chunk_30.npy: 2.52 MB\nlfcc_chunk_31.npy: 2.52 MB\nlfcc_chunk_32.npy: 2.52 MB\nlfcc_chunk_33.npy: 2.52 MB\nlfcc_chunk_34.npy: 2.52 MB\nlfcc_chunk_35.npy: 2.52 MB\nlfcc_chunk_36.npy: 2.52 MB\nlfcc_chunk_37.npy: 2.52 MB\nlfcc_chunk_38.npy: 2.52 MB\nlfcc_chunk_39.npy: 2.52 MB\nlfcc_chunk_4.npy: 2.52 MB\nlfcc_chunk_40.npy: 2.52 MB\nlfcc_chunk_41.npy: 2.52 MB\nlfcc_chunk_42.npy: 2.52 MB\nlfcc_chunk_43.npy: 2.52 MB\nlfcc_chunk_44.npy: 2.52 MB\nlfcc_chunk_45.npy: 2.52 MB\nlfcc_chunk_46.npy: 2.52 MB\nlfcc_chunk_47.npy: 2.52 MB\nlfcc_chunk_48.npy: 2.52 MB\nlfcc_chunk_49.npy: 2.52 MB\nlfcc_chunk_5.npy: 2.52 MB\nlfcc_chunk_50.npy: 2.52 MB\nlfcc_chunk_51.npy: 2.52 MB\nlfcc_chunk_52.npy: 2.52 MB\nlfcc_chunk_53.npy: 2.52 MB\nlfcc_chunk_54.npy: 2.52 MB\nlfcc_chunk_55.npy: 2.52 MB\nlfcc_chunk_56.npy: 2.52 MB\nlfcc_chunk_57.npy: 2.52 MB\nlfcc_chunk_58.npy: 2.52 MB\nlfcc_chunk_59.npy: 2.52 MB\nlfcc_chunk_6.npy: 2.52 MB\nlfcc_chunk_60.npy: 2.52 MB\nlfcc_chunk_61.npy: 2.52 MB\nlfcc_chunk_62.npy: 2.52 MB\nlfcc_chunk_63.npy: 2.52 MB\nlfcc_chunk_64.npy: 2.52 MB\nlfcc_chunk_65.npy: 2.52 MB\nlfcc_chunk_66.npy: 2.52 MB\nlfcc_chunk_67.npy: 2.52 MB\nlfcc_chunk_68.npy: 2.52 MB\nlfcc_chunk_69.npy: 2.52 MB\nlfcc_chunk_7.npy: 2.52 MB\nlfcc_chunk_70.npy: 2.52 MB\nlfcc_chunk_71.npy: 2.52 MB\nlfcc_chunk_72.npy: 2.52 MB\nlfcc_chunk_73.npy: 2.52 MB\nlfcc_chunk_74.npy: 2.52 MB\nlfcc_chunk_75.npy: 2.52 MB\nlfcc_chunk_76.npy: 2.52 MB\nlfcc_chunk_77.npy: 2.52 MB\nlfcc_chunk_78.npy: 2.52 MB\nlfcc_chunk_79.npy: 2.52 MB\nlfcc_chunk_8.npy: 2.52 MB\nlfcc_chunk_80.npy: 2.52 MB\nlfcc_chunk_81.npy: 2.52 MB\nlfcc_chunk_82.npy: 2.52 MB\nlfcc_chunk_83.npy: 2.52 MB\nlfcc_chunk_84.npy: 2.52 MB\nlfcc_chunk_85.npy: 2.52 MB\nlfcc_chunk_86.npy: 2.52 MB\nlfcc_chunk_87.npy: 2.52 MB\nlfcc_chunk_88.npy: 2.52 MB\nlfcc_chunk_89.npy: 2.52 MB\nlfcc_chunk_9.npy: 2.52 MB\nlfcc_chunk_90.npy: 2.52 MB\nlfcc_chunk_91.npy: 2.52 MB\nlfcc_chunk_92.npy: 2.52 MB\nlfcc_chunk_93.npy: 2.52 MB\nlfcc_chunk_94.npy: 2.52 MB\nlfcc_chunk_95.npy: 2.52 MB\nlfcc_chunk_96.npy: 2.52 MB\nlfcc_chunk_97.npy: 2.52 MB\nlfcc_chunk_98.npy: 2.52 MB\nlfcc_chunk_99.npy: 2.52 MB\nmfcc_chunk_0.npy: 2.52 MB\nmfcc_chunk_1.npy: 2.52 MB\nmfcc_chunk_10.npy: 2.52 MB\nmfcc_chunk_100.npy: 2.52 MB\nmfcc_chunk_101.npy: 2.52 MB\nmfcc_chunk_102.npy: 2.52 MB\nmfcc_chunk_103.npy: 2.52 MB\nmfcc_chunk_104.npy: 2.52 MB\nmfcc_chunk_105.npy: 2.52 MB\nmfcc_chunk_106.npy: 2.52 MB\nmfcc_chunk_107.npy: 2.52 MB\nmfcc_chunk_108.npy: 2.52 MB\nmfcc_chunk_109.npy: 2.52 MB\nmfcc_chunk_11.npy: 2.52 MB\nmfcc_chunk_110.npy: 2.52 MB\nmfcc_chunk_111.npy: 2.52 MB\nmfcc_chunk_112.npy: 2.52 MB\nmfcc_chunk_113.npy: 2.52 MB\nmfcc_chunk_114.npy: 2.52 MB\nmfcc_chunk_115.npy: 2.52 MB\nmfcc_chunk_116.npy: 2.52 MB\nmfcc_chunk_117.npy: 2.52 MB\nmfcc_chunk_118.npy: 2.52 MB\nmfcc_chunk_119.npy: 2.52 MB\nmfcc_chunk_12.npy: 2.52 MB\nmfcc_chunk_120.npy: 2.52 MB\nmfcc_chunk_121.npy: 2.52 MB\nmfcc_chunk_122.npy: 2.52 MB\nmfcc_chunk_123.npy: 2.52 MB\nmfcc_chunk_124.npy: 2.52 MB\nmfcc_chunk_125.npy: 2.52 MB\nmfcc_chunk_126.npy: 2.52 MB\nmfcc_chunk_127.npy: 2.52 MB\nmfcc_chunk_128.npy: 2.52 MB\nmfcc_chunk_129.npy: 2.52 MB\nmfcc_chunk_13.npy: 2.52 MB\nmfcc_chunk_130.npy: 2.52 MB\nmfcc_chunk_131.npy: 2.52 MB\nmfcc_chunk_132.npy: 2.52 MB\nmfcc_chunk_133.npy: 2.52 MB\nmfcc_chunk_134.npy: 2.52 MB\nmfcc_chunk_135.npy: 2.52 MB\nmfcc_chunk_136.npy: 2.52 MB\nmfcc_chunk_137.npy: 2.52 MB\nmfcc_chunk_138.npy: 2.52 MB\nmfcc_chunk_139.npy: 2.52 MB\nmfcc_chunk_14.npy: 2.52 MB\nmfcc_chunk_140.npy: 2.52 MB\nmfcc_chunk_141.npy: 2.52 MB\nmfcc_chunk_142.npy: 2.52 MB\nmfcc_chunk_143.npy: 2.52 MB\nmfcc_chunk_144.npy: 2.52 MB\nmfcc_chunk_145.npy: 2.52 MB\nmfcc_chunk_146.npy: 2.52 MB\nmfcc_chunk_147.npy: 2.52 MB\nmfcc_chunk_148.npy: 2.52 MB\nmfcc_chunk_149.npy: 2.52 MB\nmfcc_chunk_15.npy: 2.52 MB\nmfcc_chunk_150.npy: 2.52 MB\nmfcc_chunk_151.npy: 2.52 MB\nmfcc_chunk_152.npy: 2.52 MB\nmfcc_chunk_153.npy: 2.52 MB\nmfcc_chunk_154.npy: 2.52 MB\nmfcc_chunk_155.npy: 2.52 MB\nmfcc_chunk_156.npy: 2.52 MB\nmfcc_chunk_157.npy: 2.52 MB\nmfcc_chunk_158.npy: 2.52 MB\nmfcc_chunk_159.npy: 2.52 MB\nmfcc_chunk_16.npy: 2.52 MB\nmfcc_chunk_160.npy: 2.52 MB\nmfcc_chunk_161.npy: 2.52 MB\nmfcc_chunk_162.npy: 2.52 MB\nmfcc_chunk_163.npy: 2.52 MB\nmfcc_chunk_164.npy: 2.52 MB\nmfcc_chunk_165.npy: 2.52 MB\nmfcc_chunk_166.npy: 2.52 MB\nmfcc_chunk_167.npy: 2.52 MB\nmfcc_chunk_168.npy: 2.52 MB\nmfcc_chunk_169.npy: 2.52 MB\nmfcc_chunk_17.npy: 2.52 MB\nmfcc_chunk_170.npy: 2.52 MB\nmfcc_chunk_171.npy: 2.52 MB\nmfcc_chunk_172.npy: 2.52 MB\nmfcc_chunk_173.npy: 2.52 MB\nmfcc_chunk_174.npy: 2.52 MB\nmfcc_chunk_175.npy: 2.52 MB\nmfcc_chunk_176.npy: 2.52 MB\nmfcc_chunk_177.npy: 2.52 MB\nmfcc_chunk_178.npy: 2.52 MB\nmfcc_chunk_179.npy: 2.52 MB\nmfcc_chunk_18.npy: 2.52 MB\nmfcc_chunk_180.npy: 2.52 MB\nmfcc_chunk_181.npy: 2.52 MB\nmfcc_chunk_182.npy: 2.52 MB\nmfcc_chunk_183.npy: 2.52 MB\nmfcc_chunk_184.npy: 2.52 MB\nmfcc_chunk_185.npy: 2.52 MB\nmfcc_chunk_186.npy: 2.52 MB\nmfcc_chunk_187.npy: 2.52 MB\nmfcc_chunk_188.npy: 2.52 MB\nmfcc_chunk_189.npy: 2.52 MB\nmfcc_chunk_19.npy: 2.52 MB\nmfcc_chunk_190.npy: 2.52 MB\nmfcc_chunk_191.npy: 2.52 MB\nmfcc_chunk_192.npy: 2.52 MB\nmfcc_chunk_193.npy: 2.52 MB\nmfcc_chunk_194.npy: 2.52 MB\nmfcc_chunk_195.npy: 2.52 MB\nmfcc_chunk_196.npy: 2.52 MB\nmfcc_chunk_197.npy: 2.52 MB\nmfcc_chunk_198.npy: 2.52 MB\nmfcc_chunk_199.npy: 2.52 MB\nmfcc_chunk_2.npy: 2.52 MB\nmfcc_chunk_20.npy: 2.52 MB\nmfcc_chunk_200.npy: 2.52 MB\nmfcc_chunk_201.npy: 2.52 MB\nmfcc_chunk_202.npy: 2.52 MB\nmfcc_chunk_203.npy: 2.52 MB\nmfcc_chunk_204.npy: 2.52 MB\nmfcc_chunk_205.npy: 2.52 MB\nmfcc_chunk_206.npy: 2.52 MB\nmfcc_chunk_207.npy: 2.52 MB\nmfcc_chunk_208.npy: 2.52 MB\nmfcc_chunk_209.npy: 2.52 MB\nmfcc_chunk_21.npy: 2.52 MB\nmfcc_chunk_210.npy: 2.52 MB\nmfcc_chunk_211.npy: 2.52 MB\nmfcc_chunk_212.npy: 2.52 MB\nmfcc_chunk_213.npy: 2.52 MB\nmfcc_chunk_214.npy: 2.52 MB\nmfcc_chunk_215.npy: 2.52 MB\nmfcc_chunk_216.npy: 2.52 MB\nmfcc_chunk_217.npy: 2.52 MB\nmfcc_chunk_218.npy: 2.52 MB\nmfcc_chunk_219.npy: 2.52 MB\nmfcc_chunk_22.npy: 2.52 MB\nmfcc_chunk_220.npy: 2.52 MB\nmfcc_chunk_221.npy: 2.52 MB\nmfcc_chunk_222.npy: 2.52 MB\nmfcc_chunk_223.npy: 2.52 MB\nmfcc_chunk_224.npy: 2.52 MB\nmfcc_chunk_225.npy: 2.52 MB\nmfcc_chunk_226.npy: 2.52 MB\nmfcc_chunk_227.npy: 2.52 MB\nmfcc_chunk_228.npy: 2.52 MB\nmfcc_chunk_229.npy: 2.52 MB\nmfcc_chunk_23.npy: 2.52 MB\nmfcc_chunk_230.npy: 2.52 MB\nmfcc_chunk_231.npy: 2.52 MB\nmfcc_chunk_232.npy: 2.52 MB\nmfcc_chunk_233.npy: 2.52 MB\nmfcc_chunk_234.npy: 2.52 MB\nmfcc_chunk_235.npy: 2.52 MB\nmfcc_chunk_236.npy: 2.52 MB\nmfcc_chunk_237.npy: 2.52 MB\nmfcc_chunk_238.npy: 2.52 MB\nmfcc_chunk_239.npy: 2.52 MB\nmfcc_chunk_24.npy: 2.52 MB\nmfcc_chunk_240.npy: 2.52 MB\nmfcc_chunk_241.npy: 2.52 MB\nmfcc_chunk_242.npy: 2.52 MB\nmfcc_chunk_243.npy: 2.52 MB\nmfcc_chunk_244.npy: 2.52 MB\nmfcc_chunk_245.npy: 2.52 MB\nmfcc_chunk_246.npy: 2.52 MB\nmfcc_chunk_247.npy: 2.52 MB\nmfcc_chunk_248.npy: 2.52 MB\nmfcc_chunk_249.npy: 2.52 MB\nmfcc_chunk_25.npy: 2.52 MB\nmfcc_chunk_250.npy: 2.52 MB\nmfcc_chunk_251.npy: 2.52 MB\nmfcc_chunk_252.npy: 2.52 MB\nmfcc_chunk_253.npy: 2.52 MB\nmfcc_chunk_254.npy: 2.52 MB\nmfcc_chunk_255.npy: 2.52 MB\nmfcc_chunk_256.npy: 2.52 MB\nmfcc_chunk_257.npy: 2.52 MB\nmfcc_chunk_258.npy: 2.52 MB\nmfcc_chunk_259.npy: 2.52 MB\nmfcc_chunk_26.npy: 2.52 MB\nmfcc_chunk_260.npy: 2.52 MB\nmfcc_chunk_261.npy: 2.52 MB\nmfcc_chunk_262.npy: 2.52 MB\nmfcc_chunk_263.npy: 2.52 MB\nmfcc_chunk_264.npy: 2.52 MB\nmfcc_chunk_265.npy: 2.52 MB\nmfcc_chunk_266.npy: 2.52 MB\nmfcc_chunk_267.npy: 2.52 MB\nmfcc_chunk_27.npy: 2.52 MB\nmfcc_chunk_28.npy: 2.52 MB\nmfcc_chunk_29.npy: 2.52 MB\nmfcc_chunk_3.npy: 2.52 MB\nmfcc_chunk_30.npy: 2.52 MB\nmfcc_chunk_31.npy: 2.52 MB\nmfcc_chunk_32.npy: 2.52 MB\nmfcc_chunk_33.npy: 2.52 MB\nmfcc_chunk_34.npy: 2.52 MB\nmfcc_chunk_35.npy: 2.52 MB\nmfcc_chunk_36.npy: 2.52 MB\nmfcc_chunk_37.npy: 2.52 MB\nmfcc_chunk_38.npy: 2.52 MB\nmfcc_chunk_39.npy: 2.52 MB\nmfcc_chunk_4.npy: 2.52 MB\nmfcc_chunk_40.npy: 2.52 MB\nmfcc_chunk_41.npy: 2.52 MB\nmfcc_chunk_42.npy: 2.52 MB\nmfcc_chunk_43.npy: 2.52 MB\nmfcc_chunk_44.npy: 2.52 MB\nmfcc_chunk_45.npy: 2.52 MB\nmfcc_chunk_46.npy: 2.52 MB\nmfcc_chunk_47.npy: 2.52 MB\nmfcc_chunk_48.npy: 2.52 MB\nmfcc_chunk_49.npy: 2.52 MB\nmfcc_chunk_5.npy: 2.52 MB\nmfcc_chunk_50.npy: 2.52 MB\nmfcc_chunk_51.npy: 2.52 MB\nmfcc_chunk_52.npy: 2.52 MB\nmfcc_chunk_53.npy: 2.52 MB\nmfcc_chunk_54.npy: 2.52 MB\nmfcc_chunk_55.npy: 2.52 MB\nmfcc_chunk_56.npy: 2.52 MB\nmfcc_chunk_57.npy: 2.52 MB\nmfcc_chunk_58.npy: 2.52 MB\nmfcc_chunk_59.npy: 2.52 MB\nmfcc_chunk_6.npy: 2.52 MB\nmfcc_chunk_60.npy: 2.52 MB\nmfcc_chunk_61.npy: 2.52 MB\nmfcc_chunk_62.npy: 2.52 MB\nmfcc_chunk_63.npy: 2.52 MB\nmfcc_chunk_64.npy: 2.52 MB\nmfcc_chunk_65.npy: 2.52 MB\nmfcc_chunk_66.npy: 2.52 MB\nmfcc_chunk_67.npy: 2.52 MB\nmfcc_chunk_68.npy: 2.52 MB\nmfcc_chunk_69.npy: 2.52 MB\nmfcc_chunk_7.npy: 2.52 MB\nmfcc_chunk_70.npy: 2.52 MB\nmfcc_chunk_71.npy: 2.52 MB\nmfcc_chunk_72.npy: 2.52 MB\nmfcc_chunk_73.npy: 2.52 MB\nmfcc_chunk_74.npy: 2.52 MB\nmfcc_chunk_75.npy: 2.52 MB\nmfcc_chunk_76.npy: 2.52 MB\nmfcc_chunk_77.npy: 2.52 MB\nmfcc_chunk_78.npy: 2.52 MB\nmfcc_chunk_79.npy: 2.52 MB\nmfcc_chunk_8.npy: 2.52 MB\nmfcc_chunk_80.npy: 2.52 MB\nmfcc_chunk_81.npy: 2.52 MB\nmfcc_chunk_82.npy: 2.52 MB\nmfcc_chunk_83.npy: 2.52 MB\nmfcc_chunk_84.npy: 2.52 MB\nmfcc_chunk_85.npy: 2.52 MB\nmfcc_chunk_86.npy: 2.52 MB\nmfcc_chunk_87.npy: 2.52 MB\nmfcc_chunk_88.npy: 2.52 MB\nmfcc_chunk_89.npy: 2.52 MB\nmfcc_chunk_9.npy: 2.52 MB\nmfcc_chunk_90.npy: 2.52 MB\nmfcc_chunk_91.npy: 2.52 MB\nmfcc_chunk_92.npy: 2.52 MB\nmfcc_chunk_93.npy: 2.52 MB\nmfcc_chunk_94.npy: 2.52 MB\nmfcc_chunk_95.npy: 2.52 MB\nmfcc_chunk_96.npy: 2.52 MB\nmfcc_chunk_97.npy: 2.52 MB\nmfcc_chunk_98.npy: 2.52 MB\nmfcc_chunk_99.npy: 2.52 MB\ny_chunk_0.npy: 0.01 MB\ny_chunk_1.npy: 0.01 MB\ny_chunk_10.npy: 0.01 MB\ny_chunk_100.npy: 0.01 MB\ny_chunk_101.npy: 0.01 MB\ny_chunk_102.npy: 0.01 MB\ny_chunk_103.npy: 0.01 MB\ny_chunk_104.npy: 0.01 MB\ny_chunk_105.npy: 0.01 MB\ny_chunk_106.npy: 0.01 MB\ny_chunk_107.npy: 0.01 MB\ny_chunk_108.npy: 0.01 MB\ny_chunk_109.npy: 0.01 MB\ny_chunk_11.npy: 0.01 MB\ny_chunk_110.npy: 0.01 MB\ny_chunk_111.npy: 0.01 MB\ny_chunk_112.npy: 0.01 MB\ny_chunk_113.npy: 0.01 MB\ny_chunk_114.npy: 0.01 MB\ny_chunk_115.npy: 0.01 MB\ny_chunk_116.npy: 0.01 MB\ny_chunk_117.npy: 0.01 MB\ny_chunk_118.npy: 0.01 MB\ny_chunk_119.npy: 0.01 MB\ny_chunk_12.npy: 0.01 MB\ny_chunk_120.npy: 0.01 MB\ny_chunk_121.npy: 0.01 MB\ny_chunk_122.npy: 0.01 MB\ny_chunk_123.npy: 0.01 MB\ny_chunk_124.npy: 0.01 MB\ny_chunk_125.npy: 0.01 MB\ny_chunk_126.npy: 0.01 MB\ny_chunk_127.npy: 0.01 MB\ny_chunk_128.npy: 0.01 MB\ny_chunk_129.npy: 0.01 MB\ny_chunk_13.npy: 0.01 MB\ny_chunk_130.npy: 0.01 MB\ny_chunk_131.npy: 0.01 MB\ny_chunk_132.npy: 0.01 MB\ny_chunk_133.npy: 0.01 MB\ny_chunk_134.npy: 0.01 MB\ny_chunk_135.npy: 0.01 MB\ny_chunk_136.npy: 0.01 MB\ny_chunk_137.npy: 0.01 MB\ny_chunk_138.npy: 0.01 MB\ny_chunk_139.npy: 0.01 MB\ny_chunk_14.npy: 0.01 MB\ny_chunk_140.npy: 0.01 MB\ny_chunk_141.npy: 0.01 MB\ny_chunk_142.npy: 0.01 MB\ny_chunk_143.npy: 0.01 MB\ny_chunk_144.npy: 0.01 MB\ny_chunk_145.npy: 0.01 MB\ny_chunk_146.npy: 0.01 MB\ny_chunk_147.npy: 0.01 MB\ny_chunk_148.npy: 0.01 MB\ny_chunk_149.npy: 0.01 MB\ny_chunk_15.npy: 0.01 MB\ny_chunk_150.npy: 0.01 MB\ny_chunk_151.npy: 0.01 MB\ny_chunk_152.npy: 0.01 MB\ny_chunk_153.npy: 0.01 MB\ny_chunk_154.npy: 0.01 MB\ny_chunk_155.npy: 0.01 MB\ny_chunk_156.npy: 0.01 MB\ny_chunk_157.npy: 0.01 MB\ny_chunk_158.npy: 0.01 MB\ny_chunk_159.npy: 0.01 MB\ny_chunk_16.npy: 0.01 MB\ny_chunk_160.npy: 0.01 MB\ny_chunk_161.npy: 0.01 MB\ny_chunk_162.npy: 0.01 MB\ny_chunk_163.npy: 0.01 MB\ny_chunk_164.npy: 0.01 MB\ny_chunk_165.npy: 0.01 MB\ny_chunk_166.npy: 0.01 MB\ny_chunk_167.npy: 0.01 MB\ny_chunk_168.npy: 0.01 MB\ny_chunk_169.npy: 0.01 MB\ny_chunk_17.npy: 0.01 MB\ny_chunk_170.npy: 0.01 MB\ny_chunk_171.npy: 0.01 MB\ny_chunk_172.npy: 0.01 MB\ny_chunk_173.npy: 0.01 MB\ny_chunk_174.npy: 0.01 MB\ny_chunk_175.npy: 0.01 MB\ny_chunk_176.npy: 0.01 MB\ny_chunk_177.npy: 0.01 MB\ny_chunk_178.npy: 0.01 MB\ny_chunk_179.npy: 0.01 MB\ny_chunk_18.npy: 0.01 MB\ny_chunk_180.npy: 0.01 MB\ny_chunk_181.npy: 0.01 MB\ny_chunk_182.npy: 0.01 MB\ny_chunk_183.npy: 0.01 MB\ny_chunk_184.npy: 0.01 MB\ny_chunk_185.npy: 0.01 MB\ny_chunk_186.npy: 0.01 MB\ny_chunk_187.npy: 0.01 MB\ny_chunk_188.npy: 0.01 MB\ny_chunk_189.npy: 0.01 MB\ny_chunk_19.npy: 0.01 MB\ny_chunk_190.npy: 0.01 MB\ny_chunk_191.npy: 0.01 MB\ny_chunk_192.npy: 0.01 MB\ny_chunk_193.npy: 0.01 MB\ny_chunk_194.npy: 0.01 MB\ny_chunk_195.npy: 0.01 MB\ny_chunk_196.npy: 0.01 MB\ny_chunk_197.npy: 0.01 MB\ny_chunk_198.npy: 0.01 MB\ny_chunk_199.npy: 0.01 MB\ny_chunk_2.npy: 0.01 MB\ny_chunk_20.npy: 0.01 MB\ny_chunk_200.npy: 0.01 MB\ny_chunk_201.npy: 0.01 MB\ny_chunk_202.npy: 0.01 MB\ny_chunk_203.npy: 0.01 MB\ny_chunk_204.npy: 0.01 MB\ny_chunk_205.npy: 0.01 MB\ny_chunk_206.npy: 0.01 MB\ny_chunk_207.npy: 0.01 MB\ny_chunk_208.npy: 0.01 MB\ny_chunk_209.npy: 0.01 MB\ny_chunk_21.npy: 0.01 MB\ny_chunk_210.npy: 0.01 MB\ny_chunk_211.npy: 0.01 MB\ny_chunk_212.npy: 0.01 MB\ny_chunk_213.npy: 0.01 MB\ny_chunk_214.npy: 0.01 MB\ny_chunk_215.npy: 0.01 MB\ny_chunk_216.npy: 0.01 MB\ny_chunk_217.npy: 0.01 MB\ny_chunk_218.npy: 0.01 MB\ny_chunk_219.npy: 0.01 MB\ny_chunk_22.npy: 0.01 MB\ny_chunk_220.npy: 0.01 MB\ny_chunk_221.npy: 0.01 MB\ny_chunk_222.npy: 0.01 MB\ny_chunk_223.npy: 0.01 MB\ny_chunk_224.npy: 0.01 MB\ny_chunk_225.npy: 0.01 MB\ny_chunk_226.npy: 0.01 MB\ny_chunk_227.npy: 0.01 MB\ny_chunk_228.npy: 0.01 MB\ny_chunk_229.npy: 0.01 MB\ny_chunk_23.npy: 0.01 MB\ny_chunk_230.npy: 0.01 MB\ny_chunk_231.npy: 0.01 MB\ny_chunk_232.npy: 0.01 MB\ny_chunk_233.npy: 0.01 MB\ny_chunk_234.npy: 0.01 MB\ny_chunk_235.npy: 0.01 MB\ny_chunk_236.npy: 0.01 MB\ny_chunk_237.npy: 0.01 MB\ny_chunk_238.npy: 0.01 MB\ny_chunk_239.npy: 0.01 MB\ny_chunk_24.npy: 0.01 MB\ny_chunk_240.npy: 0.01 MB\ny_chunk_241.npy: 0.01 MB\ny_chunk_242.npy: 0.01 MB\ny_chunk_243.npy: 0.01 MB\ny_chunk_244.npy: 0.01 MB\ny_chunk_245.npy: 0.01 MB\ny_chunk_246.npy: 0.01 MB\ny_chunk_247.npy: 0.01 MB\ny_chunk_248.npy: 0.01 MB\ny_chunk_249.npy: 0.01 MB\ny_chunk_25.npy: 0.01 MB\ny_chunk_250.npy: 0.01 MB\ny_chunk_251.npy: 0.01 MB\ny_chunk_252.npy: 0.01 MB\ny_chunk_253.npy: 0.01 MB\ny_chunk_254.npy: 0.01 MB\ny_chunk_255.npy: 0.01 MB\ny_chunk_256.npy: 0.01 MB\ny_chunk_257.npy: 0.01 MB\ny_chunk_258.npy: 0.01 MB\ny_chunk_259.npy: 0.01 MB\ny_chunk_26.npy: 0.01 MB\ny_chunk_260.npy: 0.01 MB\ny_chunk_261.npy: 0.01 MB\ny_chunk_262.npy: 0.01 MB\ny_chunk_263.npy: 0.01 MB\ny_chunk_264.npy: 0.01 MB\ny_chunk_265.npy: 0.01 MB\ny_chunk_266.npy: 0.01 MB\ny_chunk_267.npy: 0.01 MB\ny_chunk_27.npy: 0.01 MB\ny_chunk_28.npy: 0.01 MB\ny_chunk_29.npy: 0.01 MB\ny_chunk_3.npy: 0.01 MB\ny_chunk_30.npy: 0.01 MB\ny_chunk_31.npy: 0.01 MB\ny_chunk_32.npy: 0.01 MB\ny_chunk_33.npy: 0.01 MB\ny_chunk_34.npy: 0.01 MB\ny_chunk_35.npy: 0.01 MB\ny_chunk_36.npy: 0.01 MB\ny_chunk_37.npy: 0.01 MB\ny_chunk_38.npy: 0.01 MB\ny_chunk_39.npy: 0.01 MB\ny_chunk_4.npy: 0.01 MB\ny_chunk_40.npy: 0.01 MB\ny_chunk_41.npy: 0.01 MB\ny_chunk_42.npy: 0.01 MB\ny_chunk_43.npy: 0.01 MB\ny_chunk_44.npy: 0.01 MB\ny_chunk_45.npy: 0.01 MB\ny_chunk_46.npy: 0.01 MB\ny_chunk_47.npy: 0.01 MB\ny_chunk_48.npy: 0.01 MB\ny_chunk_49.npy: 0.01 MB\ny_chunk_5.npy: 0.01 MB\ny_chunk_50.npy: 0.01 MB\ny_chunk_51.npy: 0.01 MB\ny_chunk_52.npy: 0.01 MB\ny_chunk_53.npy: 0.01 MB\ny_chunk_54.npy: 0.01 MB\ny_chunk_55.npy: 0.01 MB\ny_chunk_56.npy: 0.01 MB\ny_chunk_57.npy: 0.01 MB\ny_chunk_58.npy: 0.01 MB\ny_chunk_59.npy: 0.01 MB\ny_chunk_6.npy: 0.01 MB\ny_chunk_60.npy: 0.01 MB\ny_chunk_61.npy: 0.01 MB\ny_chunk_62.npy: 0.01 MB\ny_chunk_63.npy: 0.01 MB\ny_chunk_64.npy: 0.01 MB\ny_chunk_65.npy: 0.01 MB\ny_chunk_66.npy: 0.01 MB\ny_chunk_67.npy: 0.01 MB\ny_chunk_68.npy: 0.01 MB\ny_chunk_69.npy: 0.01 MB\ny_chunk_7.npy: 0.01 MB\ny_chunk_70.npy: 0.01 MB\ny_chunk_71.npy: 0.01 MB\ny_chunk_72.npy: 0.01 MB\ny_chunk_73.npy: 0.01 MB\ny_chunk_74.npy: 0.01 MB\ny_chunk_75.npy: 0.01 MB\ny_chunk_76.npy: 0.01 MB\ny_chunk_77.npy: 0.01 MB\ny_chunk_78.npy: 0.01 MB\ny_chunk_79.npy: 0.01 MB\ny_chunk_8.npy: 0.01 MB\ny_chunk_80.npy: 0.01 MB\ny_chunk_81.npy: 0.01 MB\ny_chunk_82.npy: 0.01 MB\ny_chunk_83.npy: 0.01 MB\ny_chunk_84.npy: 0.01 MB\ny_chunk_85.npy: 0.01 MB\ny_chunk_86.npy: 0.01 MB\ny_chunk_87.npy: 0.01 MB\ny_chunk_88.npy: 0.01 MB\ny_chunk_89.npy: 0.01 MB\ny_chunk_9.npy: 0.01 MB\ny_chunk_90.npy: 0.01 MB\ny_chunk_91.npy: 0.01 MB\ny_chunk_92.npy: 0.01 MB\ny_chunk_93.npy: 0.01 MB\ny_chunk_94.npy: 0.01 MB\ny_chunk_95.npy: 0.01 MB\ny_chunk_96.npy: 0.01 MB\ny_chunk_97.npy: 0.01 MB\ny_chunk_98.npy: 0.01 MB\ny_chunk_99.npy: 0.01 MB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Model Training and Testing - Datasets aggregated","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport psutil\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nepochs = 20  # Keep epochs with early stopping\n\n# Dataset Class\nclass AudioDataset(Dataset):\n    def __init__(self, chunk_dir, chunk_indices, dataset_type=\"train\"):\n        self.chunk_dir = chunk_dir\n        self.dataset_type = dataset_type\n        \n        # Verify that the directory exists\n        if not os.path.exists(chunk_dir):\n            raise FileNotFoundError(f\"Chunk directory {chunk_dir} does not exist.\")\n        \n        # Look for MFCC chunk files with the correct names\n        self.chunk_files = sorted([f for f in os.listdir(chunk_dir) if f.startswith(\"mfcc_chunk_\") and f.endswith(\".npy\")])\n        \n        # Check if any chunk files were found; debugging for previous errors\n        if not self.chunk_files:\n            raise FileNotFoundError(f\"No MFCC chunk files found in {chunk_dir}. Expected files like 'mfcc_chunk_0.npy'.\")\n        \n        print(f\"Found {len(self.chunk_files)} chunk files in {chunk_dir}. First few: {self.chunk_files[:5]}\")\n        \n        self.chunk_size = 646  # Fixed chunk size from preprocessing\n        self.num_chunks = len(self.chunk_files)\n        self.total_samples = self.num_chunks * self.chunk_size\n        \n        # Filter indices to ensure they are within bounds\n        self.indices = [idx for idx in chunk_indices if idx < self.total_samples]\n        \n        # Check if indices are empty\n        if not self.indices:\n            raise ValueError(f\"No valid indices for {self.dataset_type} dataset. \"\n                            f\"Total samples: {self.total_samples}, but chunk_indices range is {min(chunk_indices)} to {max(chunk_indices)}.\")\n        \n        print(f\"Dataset ({self.dataset_type}) initialized with {len(self.indices)} samples. \"\n              f\"Index range: {self.indices[0]} to {self.indices[-1]}\")\n    \n    def __len__(self):\n        return len(self.indices)\n    \n    def __getitem__(self, idx):\n        if idx >= len(self.indices):\n            raise IndexError(f\"Index {idx} is out of bounds for dataset with length {len(self.indices)}\")\n        \n        # Map global index to chunk and local index\n        global_idx = self.indices[idx]\n        chunk_idx = global_idx // self.chunk_size\n        local_idx = global_idx % self.chunk_size\n        \n        # Load the chunks with the correct file names\n        mfcc_chunk = np.load(os.path.join(self.chunk_dir, f\"mfcc_chunk_{chunk_idx}.npy\"), mmap_mode='r')\n        lfcc_chunk = np.load(os.path.join(self.chunk_dir, f\"lfcc_chunk_{chunk_idx}.npy\"), mmap_mode='r')\n        chroma_chunk = np.load(os.path.join(self.chunk_dir, f\"chroma_chunk_{chunk_idx}.npy\"), mmap_mode='r')\n        y_chunk = np.load(os.path.join(self.chunk_dir, f\"y_chunk_{chunk_idx}.npy\"), mmap_mode='r')\n        \n        # Extract the sample\n        mfcc = torch.FloatTensor(mfcc_chunk[local_idx])  # Shape: (1, 32, 32)\n        lfcc = torch.FloatTensor(lfcc_chunk[local_idx])  # Shape: (1, 32, 32)\n        chroma = torch.FloatTensor(chroma_chunk[local_idx]).unsqueeze(0)  # Shape: (12, 32) -> (1, 12, 32)\n        y = torch.LongTensor([y_chunk[local_idx]])[0]  # Single label (0 or 1)\n        \n        # Normalize features (zero mean, unit variance)\n        mfcc = (mfcc - mfcc.mean()) / (mfcc.std() + 1e-8)\n        lfcc = (lfcc - lfcc.mean()) / (lfcc.std() + 1e-8)\n        chroma = (chroma - chroma.mean()) / (chroma.std() + 1e-8)\n        \n        # Add noise to features during training for data augmentation\n        if self.dataset_type == \"train\":\n            noise_factor = 0.1\n            mfcc += torch.randn_like(mfcc) * noise_factor\n            lfcc += torch.randn_like(lfcc) * noise_factor\n            chroma += torch.randn_like(chroma) * noise_factor\n        \n        return mfcc, lfcc, chroma, y\n\n# MFAAN Model with 1D Convolutions\nclass MFAAN(nn.Module):\n    def __init__(self):\n        super(MFAAN, self).__init__()\n        # MFCC Path: Input shape (batch, 32, 32)\n        self.path_mfcc = nn.Sequential(\n            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),  # Reduced to 16\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),  # (batch, 16, 16)\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),  # (batch, 32, 16)\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)  # (batch, 32, 8)\n        )\n        \n        # LFCC Path: Input shape (batch, 32, 32)\n        self.path_lfcc = nn.Sequential(\n            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),  # Reduced to 16\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),  # (batch, 16, 16)\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),  # (batch, 32, 16)\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)  # (batch, 32, 8)\n        )\n        \n        # Chroma Path: Input shape (batch, 12, 32)\n        self.path_chroma = nn.Sequential(\n            nn.Conv1d(in_channels=12, out_channels=16, kernel_size=3, stride=1, padding=1),  # Reduced to 16\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),  # (batch, 16, 16)\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),  # (batch, 32, 16)\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)  # (batch, 32, 8)\n        )\n        \n        # Fully connected layers after fusion\n        # Each path outputs (batch, 32, 8), so after flattening and concatenation: 32 * 8 * 3 = 768\n        self.fc1 = nn.Linear(32 * 8 * 3, 256)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, 2)  # Binary classification (real vs fake)\n    \n    def forward(self, mfcc, lfcc, chroma):\n        mfcc = mfcc.squeeze(1)  # (batch, 1, 32, 32) -> (batch, 32, 32)\n        lfcc = lfcc.squeeze(1)  # (batch, 1, 32, 32) -> (batch, 32, 32)\n        chroma = chroma.squeeze(1)  # (batch, 1, 12, 32) -> (batch, 12, 32)\n        \n        # Process each feature through their path\n        mfcc_out = self.path_mfcc(mfcc)  # (batch, 32, 8)\n        lfcc_out = self.path_lfcc(lfcc)  # (batch, 32, 8)\n        chroma_out = self.path_chroma(chroma)  # (batch, 32, 8)\n        \n        # Flatten and concatenate - finally\n        mfcc_flat = mfcc_out.view(mfcc_out.size(0), -1)  # (batch, 32 * 8)\n        lfcc_flat = lfcc_out.view(lfcc_out.size(0), -1)  # (batch, 32 * 8)\n        chroma_flat = chroma_out.view(chroma_out.size(0), -1)  # (batch, 32 * 8)\n        fused = torch.cat((mfcc_flat, lfcc_flat, chroma_flat), dim=1)  # (batch, 32 * 8 * 3)\n        \n        # Pass through fully connected layers\n        x = F.relu(self.fc1(fused))\n        x = self.dropout(x)\n        output = self.fc2(x)\n        return output\n\n# Function to compute Equal Error Rate (EER)\ndef compute_eer(labels, scores):\n    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n    fnr = 1 - tpr\n    eer_threshold = thresholds[np.nanargmin(np.absolute(fnr - fpr))]\n    eer = fpr[np.nanargmin(np.absolute(fnr - fpr))]\n    return eer\n\nchunk_dir = \"/kaggle/working/preprocessed_chunks_268\"\ntotal_samples = 173128\n\n# For stratified split\nall_labels = []\nfor chunk_idx in range(268):\n    y_chunk = np.load(os.path.join(chunk_dir, f\"y_chunk_{chunk_idx}.npy\"))\n    all_labels.extend(y_chunk)\nall_labels = np.array(all_labels)\n\nindices = list(range(len(all_labels)))\n\n# Stratified split: train (80%), val (10%), test (10%)\ntrain_indices, temp_indices, train_labels, temp_labels = train_test_split(\n    indices, all_labels, test_size=0.2, stratify=all_labels, random_state=42\n)\nval_indices, test_indices, val_labels, test_labels = train_test_split(\n    temp_indices, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n)\n\nprint(f\"Train samples: {len(train_indices)}, Val samples: {len(val_indices)}, Test samples: {len(test_indices)}\")\nprint(\"Train class distribution:\", np.bincount(train_labels))\nprint(\"Val class distribution:\", np.bincount(val_labels))\nprint(\"Test class distribution:\", np.bincount(test_labels))\n\ntrain_dataset = AudioDataset(chunk_dir, train_indices, dataset_type=\"train\")\nval_dataset = AudioDataset(chunk_dir, val_indices, dataset_type=\"val\")\ntest_dataset = AudioDataset(chunk_dir, test_indices, dataset_type=\"test\")\n\n# Debug - print dataset lengths\nprint(f\"Train dataset length: {len(train_dataset)}\")\nprint(f\"Val dataset length: {len(val_dataset)}\")\nprint(f\"Test dataset length: {len(test_dataset)}\")\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=32, num_workers=0)\ntest_loader = DataLoader(test_dataset, batch_size=32, num_workers=0)\n\n# Check for class imbalance and apply class weights\nclass_counts = np.bincount(all_labels)\nclass_weights = 1.0 / class_counts\nclass_weights = torch.FloatTensor(class_weights / class_weights.sum()).to(device)\nprint(f\"Class weights: {class_weights}\")\n\n# Model, Optimizer, and Loss\nmodel = MFAAN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=5e-3)\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)\n\n# Training loop - early stopping based on eer\ndef train_model(epochs=epochs, patience=5):\n    best_val_eer = float('inf')\n    patience_counter = 0\n    \n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        for batch_idx, (mfcc, lfcc, chroma, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n            mfcc, lfcc, chroma, labels = mfcc.to(device), lfcc.to(device), chroma.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(mfcc, lfcc, chroma)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n            optimizer.step()\n            running_loss += loss.item()\n        \n        # Validation\n        model.eval()\n        val_preds = []\n        val_scores = []\n        val_labels = []\n        with torch.no_grad():\n            for mfcc, lfcc, chroma, labels in val_loader:\n                mfcc, lfcc, chroma, labels = mfcc.to(device), lfcc.to(device), chroma.to(device), labels.to(device)\n                outputs = model(mfcc, lfcc, chroma)\n                probs = F.softmax(outputs, dim=1)[:, 1]  # Probability of class 1 (fake)\n                _, predicted = torch.max(outputs, 1)\n                val_preds.extend(predicted.cpu().numpy())\n                val_scores.extend(probs.cpu().numpy())\n                val_labels.extend(labels.cpu().numpy())\n        \n        val_acc = accuracy_score(val_labels, val_preds)\n        val_eer = compute_eer(val_labels, val_scores)\n        avg_loss = running_loss / len(train_loader)\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, \"\n              f\"Validation Accuracy: {val_acc * 100:.2f}%, Validation EER: {val_eer * 100:.2f}%\")\n        \n        # Test after first epoch - see how it is\n        if epoch == 0:\n            test_preds = []\n            test_scores = []\n            test_labels = []\n            with torch.no_grad():\n                for batch_idx, (mfcc, lfcc, chroma, labels) in enumerate(test_loader):\n                    mfcc, lfcc, chroma, labels = mfcc.to(device), lfcc.to(device), chroma.to(device), labels.to(device)\n                    outputs = model(mfcc, lfcc, chroma)\n                    probs = F.softmax(outputs, dim=1)[:, 1]\n                    _, predicted = torch.max(outputs, 1)\n                    test_preds.extend(predicted.cpu().numpy())\n                    test_scores.extend(probs.cpu().numpy())\n                    test_labels.extend(labels.cpu().numpy())\n            test_acc = accuracy_score(test_labels, test_preds)\n            test_eer = compute_eer(test_labels, test_scores)\n            print(f\"Test Accuracy after Epoch 1: {test_acc * 100:.2f}%, Test EER: {test_eer * 100:.2f}%\")\n        \n        # Early Stopping based on eer\n        if val_eer < best_val_eer:\n            best_val_eer = val_eer\n            patience_counter = 0\n            torch.save(model.state_dict(), \"/kaggle/working/mfaan_best.pth\")\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(\"Early stopping triggered!\")\n                break\n        \n        scheduler.step(val_eer)\n\ntrain_model(epochs=epochs, patience=5)\n\nprocess = psutil.Process()\nmem_info = process.memory_info()\nprint(f\"Memory usage after training: {mem_info.rss / 1024**2:.2f} MB\")\n\n# Final Test Evaluation with Per-Class Accuracy\nmodel.load_state_dict(torch.load(\"/kaggle/working/mfaan_best.pth\"))\nmodel.eval()\ntest_preds = []\ntest_scores = []\ntest_labels = []\nwith torch.no_grad():\n    for mfcc, lfcc, chroma, labels in test_loader:\n        mfcc, lfcc, chroma, labels = mfcc.to(device), lfcc.to(device), chroma.to(device), labels.to(device)\n        outputs = model(mfcc, lfcc, chroma)\n        probs = F.softmax(outputs, dim=1)[:, 1]\n        _, predicted = torch.max(outputs, 1)\n        test_preds.extend(predicted.cpu().numpy())\n        test_scores.extend(probs.cpu().numpy())\n        test_labels.extend(labels.cpu().numpy())\n\ntest_acc = accuracy_score(test_labels, test_preds)\ntest_eer = compute_eer(test_labels, test_scores)\n\n# Compute per-class accuracy - fake and real\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(test_labels, test_preds)\nper_class_acc = cm.diagonal() / cm.sum(axis=1)\nprint(f\"\\nFinal Test Accuracy: {test_acc * 100:.2f}%, Final Test EER: {test_eer * 100:.2f}%\")\nprint(f\"Per-class accuracy (real, fake): {per_class_acc * 100}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T09:45:21.481114Z","iopub.execute_input":"2025-04-24T09:45:21.481429Z","iopub.status.idle":"2025-04-24T10:50:03.757789Z","shell.execute_reply.started":"2025-04-24T09:45:21.481408Z","shell.execute_reply":"2025-04-24T10:50:03.757075Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nTrain samples: 138502, Val samples: 17313, Test samples: 17313\nTrain class distribution: [83775 54727]\nVal class distribution: [10472  6841]\nTest class distribution: [10472  6841]\nFound 268 chunk files in /kaggle/working/preprocessed_chunks_268. First few: ['mfcc_chunk_0.npy', 'mfcc_chunk_1.npy', 'mfcc_chunk_10.npy', 'mfcc_chunk_100.npy', 'mfcc_chunk_101.npy']\nDataset (train) initialized with 138502 samples. Index range: 125083 to 68149\nFound 268 chunk files in /kaggle/working/preprocessed_chunks_268. First few: ['mfcc_chunk_0.npy', 'mfcc_chunk_1.npy', 'mfcc_chunk_10.npy', 'mfcc_chunk_100.npy', 'mfcc_chunk_101.npy']\nDataset (val) initialized with 17313 samples. Index range: 112480 to 130832\nFound 268 chunk files in /kaggle/working/preprocessed_chunks_268. First few: ['mfcc_chunk_0.npy', 'mfcc_chunk_1.npy', 'mfcc_chunk_10.npy', 'mfcc_chunk_100.npy', 'mfcc_chunk_101.npy']\nDataset (test) initialized with 17313 samples. Index range: 168466 to 60314\nTrain dataset length: 138502\nVal dataset length: 17313\nTest dataset length: 17313\nClass weights: tensor([0.3951, 0.6049], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20: 100%|██████████| 4329/4329 [02:52<00:00, 25.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Loss: 0.2952, Validation Accuracy: 94.73%, Validation EER: 4.22%\nTest Accuracy after Epoch 1: 94.70%, Test EER: 4.27%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20: 100%|██████████| 4329/4329 [02:57<00:00, 24.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20, Loss: 0.1641, Validation Accuracy: 96.52%, Validation EER: 3.28%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20: 100%|██████████| 4329/4329 [02:53<00:00, 24.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20, Loss: 0.1368, Validation Accuracy: 97.05%, Validation EER: 2.44%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20, Loss: 0.1264, Validation Accuracy: 97.23%, Validation EER: 1.87%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20: 100%|██████████| 4329/4329 [02:55<00:00, 24.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20, Loss: 0.1215, Validation Accuracy: 98.09%, Validation EER: 1.87%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20, Loss: 0.1158, Validation Accuracy: 98.30%, Validation EER: 1.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20, Loss: 0.1104, Validation Accuracy: 98.23%, Validation EER: 1.77%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20, Loss: 0.1062, Validation Accuracy: 98.46%, Validation EER: 1.55%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20, Loss: 0.1023, Validation Accuracy: 98.32%, Validation EER: 1.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20, Loss: 0.1039, Validation Accuracy: 98.24%, Validation EER: 1.63%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20: 100%|██████████| 4329/4329 [02:53<00:00, 24.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20, Loss: 0.0905, Validation Accuracy: 98.63%, Validation EER: 1.37%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20: 100%|██████████| 4329/4329 [02:55<00:00, 24.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20, Loss: 0.0877, Validation Accuracy: 98.82%, Validation EER: 1.27%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20: 100%|██████████| 4329/4329 [02:55<00:00, 24.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20, Loss: 0.0882, Validation Accuracy: 98.78%, Validation EER: 1.23%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20, Loss: 0.0885, Validation Accuracy: 98.90%, Validation EER: 1.19%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20: 100%|██████████| 4329/4329 [02:55<00:00, 24.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20, Loss: 0.0901, Validation Accuracy: 98.53%, Validation EER: 1.33%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20, Loss: 0.0891, Validation Accuracy: 98.67%, Validation EER: 1.28%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20: 100%|██████████| 4329/4329 [02:54<00:00, 24.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20, Loss: 0.0887, Validation Accuracy: 98.80%, Validation EER: 1.21%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20: 100%|██████████| 4329/4329 [02:53<00:00, 24.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20, Loss: 0.0883, Validation Accuracy: 98.86%, Validation EER: 1.17%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20: 100%|██████████| 4329/4329 [02:52<00:00, 25.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20, Loss: 0.0898, Validation Accuracy: 98.73%, Validation EER: 1.27%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20: 100%|██████████| 4329/4329 [02:53<00:00, 24.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20, Loss: 0.0883, Validation Accuracy: 98.79%, Validation EER: 1.22%\nMemory usage after training: 4603.22 MB\n\nFinal Test Accuracy: 98.99%, Final Test EER: 1.04%\nPer-class accuracy (real, fake): [99.26470588 98.5674609 ]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\n\n#to check for calss imbalance - it exists - need to use stratified\ntrain_labels = [train_dataset[i][-1].item() for i in range(len(train_dataset))]\nval_labels = [val_dataset[i][-1].item() for i in range(len(val_dataset))]\ntest_labels = [test_dataset[i][-1].item() for i in range(len(test_dataset))]\nprint(\"Train class distribution:\", np.bincount(train_labels))\nprint(\"Val class distribution:\", np.bincount(val_labels))\nprint(\"Test class distribution:\", np.bincount(test_labels))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Multi-Lingual Audio Deepfake Detection Corpus (MLADDC):\nDataset with halftruths. \n\nInitially, testing FoR & InTheWild trained model on T2 - international languages - dataset.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torchaudio\nfrom torchaudio.transforms import MFCC, LFCC, Spectrogram\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}, GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n\n# T2 dataset path\nT2_PATH = \"/kaggle/input/mladdc-t2/T2/\"\n\n# Function to validate if a .wav file can be loaded\ndef validate_wav_file(file_path):\n    try:\n        waveform, sr = torchaudio.load(file_path)\n        if waveform.size(1) == 0:\n            print(f\"Skipping empty file: {file_path}\")\n            return False\n        return True\n    except Exception as e:\n        print(f\"Skipping invalid file: {file_path}, Error: {e}\")\n        return False\n\n# Function to collect T2 test audio files and labels\ndef get_t2_audio_files_and_labels(data_split=\"test\"):\n    audio_files = []\n    labels = []\n    counts = {\"real\": 0, \"fake\": 0}\n\n    real_path = os.path.join(T2_PATH, data_split, \"real\")\n    fake_path = os.path.join(T2_PATH, data_split, \"deepfake\")\n\n    if not os.path.exists(real_path):\n        raise FileNotFoundError(f\"Real directory not found at {real_path}\")\n    if not os.path.exists(fake_path):\n        raise FileNotFoundError(f\"Fake directory not found at {fake_path}\")\n\n    for file in os.listdir(real_path):\n        if file.endswith(\".wav\"):\n            file_path = os.path.join(real_path, file)\n            if validate_wav_file(file_path):\n                audio_files.append(file_path)\n                labels.append(0)  # Real\n                counts[\"real\"] += 1\n\n    for file in os.listdir(fake_path):\n        if file.endswith(\".wav\"):\n            file_path = os.path.join(fake_path, file)\n            if validate_wav_file(file_path):\n                audio_files.append(file_path)\n                labels.append(1)  # Fake\n                counts[\"fake\"] += 1\n\n    print(f\"T2 {data_split} Counts: Real: {counts['real']}, Fake: {counts['fake']}\")\n    return audio_files, labels\n\n# Custom Chroma-STFT implementation\ndef compute_chroma_stft(waveforms, sample_rate=16000, n_fft=2048, hop_length=512, n_chroma=12):\n    spectrogram_transform = Spectrogram(n_fft=n_fft, hop_length=hop_length, power=2.0).to(device)\n    spec = spectrogram_transform(waveforms)\n    spec = spec.squeeze(1)\n    freqs = torch.linspace(0, sample_rate / 2, steps=spec.shape[1]).to(device)\n    chroma_freqs = torch.tensor([31.25 * (2 ** (i / 12)) for i in range(12 * 4)], device=device)\n    chroma_bins = torch.zeros((n_chroma, spec.shape[1]), device=device)\n    for i in range(n_chroma):\n        center = chroma_freqs[i::12]\n        for cf in center:\n            mask = (freqs >= cf / 1.06) & (freqs <= cf * 1.06)\n            chroma_bins[i] += mask.float()\n    chroma_bins /= chroma_bins.sum(dim=1, keepdim=True).clamp(min=1e-10)\n    chroma = torch.einsum('cf,bft->bct', chroma_bins, spec)\n    return chroma\n\n# Feature Extraction for T2 test set\ndef extract_t2_features_batch(file_paths, labels, batch_size=64, max_length=16000):\n    mfcc_results = []\n    lfcc_results = []\n    chroma_results = []\n    valid_labels = []\n\n    # Use 32 coefficients for MFCC and LFCC\n    mfcc_transform = MFCC(\n        sample_rate=16000,\n        n_mfcc=32,\n        melkwargs={\"n_fft\": 2048, \"hop_length\": 512, \"n_mels\": 128}\n    ).to(device)\n    lfcc_transform = LFCC(\n        sample_rate=16000,\n        n_lfcc=32,\n        f_min=0,\n        f_max=8000,\n        n_filter=128,\n        speckwargs={\"n_fft\": 2048, \"hop_length\": 512}\n    ).to(device)\n\n    total_batches = (len(file_paths) + batch_size - 1) // batch_size\n    log_interval = max(1, total_batches // 100)\n\n    for i in tqdm(range(0, len(file_paths), batch_size), desc=\"Processing T2 Test Batches\", total=total_batches):\n        if i % (log_interval * batch_size) == 0:\n            print(f\"Processed {i // batch_size}/{total_batches} batches ({(i / len(file_paths)) * 100:.1f}%)\")\n\n        batch_files = file_paths[i:i + batch_size]\n        batch_labels = labels[i:i + batch_size]\n        waveforms = []\n        valid_indices = []\n\n        for idx, (file_path, label) in enumerate(zip(batch_files, batch_labels)):\n            try:\n                waveform, sr = torchaudio.load(file_path)\n                if waveform.shape[0] > 1:\n                    waveform = waveform.mean(dim=0, keepdim=True)\n                if sr != 16000:\n                    waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n                if waveform.size(1) > max_length:\n                    waveform = waveform[:, :max_length]\n                elif waveform.size(1) < max_length:\n                    pad_size = max_length - waveform.size(1)\n                    waveform = torch.nn.functional.pad(waveform, (0, pad_size))\n                waveforms.append(waveform)\n                valid_indices.append(idx)\n            except Exception as e:\n                print(f\"Error loading {file_path}: {e}\")\n                continue\n\n        if not waveforms:\n            continue\n\n        waveforms = torch.nn.utils.rnn.pad_sequence(waveforms, batch_first=True).to(device)\n        mfccs = mfcc_transform(waveforms)  # Expected (batch, 32, time)\n        lfccs = lfcc_transform(waveforms)  # Expected (batch, 32, time)\n        chromas = compute_chroma_stft(waveforms, sample_rate=16000, n_fft=2048, hop_length=512, n_chroma=12)  # Expected (batch, 12, time)\n\n        target_frames = 32\n        for idx in valid_indices:\n            # Process MFCC\n            mfcc = mfccs[idx]  # Expected (32, time)\n            if len(mfcc.shape) == 3:  # If (1, 32, time), remove extra dim\n                mfcc = mfcc.squeeze(0)\n            if mfcc.shape[1] > target_frames:\n                mfcc = mfcc[:, :target_frames]\n            elif mfcc.shape[1] < target_frames:\n                mfcc = torch.nn.functional.pad(mfcc, (0, target_frames - mfcc.shape[1]))\n            if mfcc.shape != (32, 32):\n                print(f\"Warning: MFCC shape after resize at index {idx}: {mfcc.shape}\")\n                continue\n            mfcc = mfcc.unsqueeze(0)  # (32, 32) -> (1, 32, 32)\n            if mfcc.shape != (1, 32, 32):\n                print(f\"Warning: Final MFCC shape mismatch at index {idx}: {mfcc.shape}\")\n                continue\n            mfcc_results.append(mfcc.cpu().numpy())\n\n            # Process LFCC\n            lfcc = lfccs[idx]\n            if len(lfcc.shape) == 3:\n                lfcc = lfcc.squeeze(0)\n            if lfcc.shape[1] > target_frames:\n                lfcc = lfcc[:, :target_frames]\n            elif lfcc.shape[1] < target_frames:\n                lfcc = torch.nn.functional.pad(lfcc, (0, target_frames - lfcc.shape[1]))\n            if lfcc.shape != (32, 32):\n                print(f\"Warning: LFCC shape after resize at index {idx}: {lfcc.shape}\")\n                continue\n            lfcc = lfcc.unsqueeze(0)  # (32, 32) -> (1, 32, 32)\n            if lfcc.shape != (1, 32, 32):\n                print(f\"Warning: Final LFCC shape mismatch at index {idx}: {lfcc.shape}\")\n                continue\n            lfcc_results.append(lfcc.cpu().numpy())\n\n            # Process Chroma\n            chroma = chromas[idx]\n            if len(chroma.shape) == 3:\n                chroma = chroma.squeeze(0)\n            if chroma.shape[1] > target_frames:\n                chroma = chroma[:, :target_frames]\n            elif chroma.shape[1] < target_frames:\n                chroma = torch.nn.functional.pad(chroma, (0, target_frames - chroma.shape[1]))\n            if chroma.shape != (12, 32):\n                print(f\"Warning: Chroma shape after resize at index {idx}: {chroma.shape}\")\n                continue\n            chroma = chroma.unsqueeze(0)  # (12, 32) -> (1, 12, 32)\n            if chroma.shape != (1, 12, 32):\n                print(f\"Warning: Final Chroma shape mismatch at index {idx}: {chroma.shape}\")\n                continue\n            chroma_results.append(chroma.cpu().numpy())\n\n            valid_labels.append(batch_labels[idx])\n\n    return mfcc_results, lfcc_results, chroma_results, valid_labels\n\n# Preprocess T2 test files\nt2_test_files, t2_test_labels = get_t2_audio_files_and_labels(\"test\")\nprint(f\"\\nTotal T2 test files before processing: {len(t2_test_files)}\")\nprint(f\"Label Distribution: Real (0): {sum(1 for label in t2_test_labels if label == 0)} \"\n      f\"({sum(1 for label in t2_test_labels if label == 0)/len(t2_test_files)*100:.2f}%), \"\n      f\"Fake (1): {sum(1 for label in t2_test_labels if label == 1)} \"\n      f\"({sum(1 for label in t2_test_labels if label == 1)/len(t2_test_files)*100:.2f}%)\")\n\n# Extract features\nt2_test_mfcc_features, t2_test_lfcc_features, t2_test_chroma_features, t2_test_y = extract_t2_features_batch(\n    t2_test_files, t2_test_labels, batch_size=64, max_length=16000\n)\n\n# Convert to numpy arrays\nt2_test_mfcc_features = np.array(t2_test_mfcc_features)  # (num_samples, 1, 32, 32)\nt2_test_lfcc_features = np.array(t2_test_lfcc_features)  # (num_samples, 1, 32, 32)\nt2_test_chroma_features = np.array(t2_test_chroma_features)  # (num_samples, 1, 12, 32)\nt2_test_y = np.array(t2_test_y)  # (num_samples,)\n\n# Debugging - validate shapes \nprint(f\"MFCC features shape: {t2_test_mfcc_features.shape}\")\nprint(f\"LFCC features shape: {t2_test_lfcc_features.shape}\")\nprint(f\"Chroma features shape: {t2_test_chroma_features.shape}\")\nprint(f\"Labels shape: {t2_test_y.shape}\")\n\n# Validate alignment\nif not (len(t2_test_mfcc_features) == len(t2_test_lfcc_features) == len(t2_test_chroma_features) == len(t2_test_y)):\n    raise ValueError(f\"Mismatch between T2 test features and labels: \"\n                     f\"MFCC: {len(t2_test_mfcc_features)}, LFCC: {len(t2_test_lfcc_features)}, \"\n                     f\"Chroma: {len(t2_test_chroma_features)}, y: {len(t2_test_y)}\")\n\n# Verify total samples\ntotal_t2_test_samples = len(t2_test_y)\nprint(f\"Total T2 test samples after feature extraction: {total_t2_test_samples}\")\n\n# Save T2 test chunks\noutput_dir_t2_test = \"/kaggle/working/preprocessed_t2_test_chunks\"\nos.makedirs(output_dir_t2_test, exist_ok=True)\n\n# Clear existing T2 test chunks\nfor f in os.listdir(output_dir_t2_test):\n    os.remove(os.path.join(output_dir_t2_test, f))\n\n# Use chunk size of 646 to match training data\nchunk_size_t2_test = 646\nnum_chunks_t2_test = (total_t2_test_samples + chunk_size_t2_test - 1) // chunk_size_t2_test\ntotal_t2_test_samples_used = num_chunks_t2_test * chunk_size_t2_test\n\nprint(f\"Total T2 test samples: {total_t2_test_samples}, Number of T2 test chunks: {num_chunks_t2_test}, \"\n      f\"T2 Test Chunk size: {chunk_size_t2_test}\")\nif total_t2_test_samples != total_t2_test_samples_used:\n    print(f\"Warning: {total_t2_test_samples_used - total_t2_test_samples} samples will be padded due to chunking.\")\n\n# Pad features and labels if needed\nif total_t2_test_samples < total_t2_test_samples_used:\n    pad_size = total_t2_test_samples_used - total_t2_test_samples\n    mfcc_pad = np.zeros((pad_size, 1, 32, 32), dtype=np.float32)\n    lfcc_pad = np.zeros((pad_size, 1, 32, 32), dtype=np.float32)\n    chroma_pad = np.zeros((pad_size, 1, 12, 32), dtype=np.float32)\n    y_pad = np.zeros(pad_size, dtype=np.int64)  # Pad with real labels (0)\n\n    t2_test_mfcc_features = np.concatenate([t2_test_mfcc_features, mfcc_pad], axis=0)\n    t2_test_lfcc_features = np.concatenate([t2_test_lfcc_features, lfcc_pad], axis=0)\n    t2_test_chroma_features = np.concatenate([t2_test_chroma_features, chroma_pad], axis=0)\n    t2_test_y = np.concatenate([t2_test_y, y_pad], axis=0)\n\n# Validate padded shapes\nprint(f\"Padded MFCC features shape: {t2_test_mfcc_features.shape}\")\nprint(f\"Padded LFCC features shape: {t2_test_lfcc_features.shape}\")\nprint(f\"Padded Chroma features shape: {t2_test_chroma_features.shape}\")\nprint(f\"Padded Labels shape: {t2_test_y.shape}\")\n\n# Save chunks\nfor i in range(0, total_t2_test_samples_used, chunk_size_t2_test):\n    chunk_idx = i // chunk_size_t2_test\n    t2_test_mfcc_chunk = t2_test_mfcc_features[i:i + chunk_size_t2_test]\n    t2_test_lfcc_chunk = t2_test_lfcc_features[i:i + chunk_size_t2_test]\n    t2_test_chroma_chunk = t2_test_chroma_features[i:i + chunk_size_t2_test]\n    t2_test_y_chunk = t2_test_y[i:i + chunk_size_t2_test]\n\n    if not (len(t2_test_mfcc_chunk) == len(t2_test_lfcc_chunk) == len(t2_test_chroma_chunk) == len(t2_test_y_chunk)):\n        raise ValueError(f\"Mismatch in T2 test chunk {chunk_idx}: \"\n                         f\"MFCC: {len(t2_test_mfcc_chunk)}, LFCC: {len(t2_test_lfcc_chunk)}, \"\n                         f\"Chroma: {len(t2_test_chroma_chunk)}, y: {len(t2_test_y_chunk)}\")\n\n    np.save(os.path.join(output_dir_t2_test, f\"t2_test_mfcc_chunk_{chunk_idx}.npy\"), t2_test_mfcc_chunk)\n    np.save(os.path.join(output_dir_t2_test, f\"t2_test_lfcc_chunk_{chunk_idx}.npy\"), t2_test_lfcc_chunk)\n    np.save(os.path.join(output_dir_t2_test, f\"t2_test_chroma_chunk_{chunk_idx}.npy\"), t2_test_chroma_chunk)\n    np.save(os.path.join(output_dir_t2_test, f\"t2_test_y_chunk_{chunk_idx}.npy\"), t2_test_y_chunk)\n    print(f\"Saved T2 test chunk {chunk_idx}: \"\n          f\"MFCC shape {t2_test_mfcc_chunk.shape}, LFCC shape {t2_test_lfcc_chunk.shape}, \"\n          f\"Chroma shape {t2_test_chroma_chunk.shape}, y shape {t2_test_y_chunk.shape}\")\n\nprint(f\"Processed and saved {total_t2_test_samples_used} T2 test audio samples in {output_dir_t2_test}!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T10:50:15.409964Z","iopub.execute_input":"2025-04-24T10:50:15.410612Z","iopub.status.idle":"2025-04-24T11:00:00.126392Z","shell.execute_reply.started":"2025-04-24T10:50:15.410588Z","shell.execute_reply":"2025-04-24T11:00:00.125692Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda, GPU: Tesla T4\nT2 test Counts: Real: 5600, Fake: 11200\n\nTotal T2 test files before processing: 16800\nLabel Distribution: Real (0): 5600 (33.33%), Fake (1): 11200 (66.67%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   0%|          | 0/263 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 0/263 batches (0.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   1%|          | 2/263 [00:01<03:24,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 2/263 batches (0.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   2%|▏         | 4/263 [00:03<03:22,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 4/263 batches (1.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   2%|▏         | 6/263 [00:04<03:25,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 6/263 batches (2.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   3%|▎         | 8/263 [00:06<03:22,  1.26it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 8/263 batches (3.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   4%|▍         | 10/263 [00:07<03:24,  1.23it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 10/263 batches (3.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   5%|▍         | 12/263 [00:09<03:17,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 12/263 batches (4.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   5%|▌         | 14/263 [00:11<03:19,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 14/263 batches (5.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   6%|▌         | 16/263 [00:12<03:15,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 16/263 batches (6.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   7%|▋         | 18/263 [00:14<03:11,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 18/263 batches (6.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   8%|▊         | 20/263 [00:15<03:09,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 20/263 batches (7.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   8%|▊         | 22/263 [00:17<03:07,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 22/263 batches (8.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:   9%|▉         | 24/263 [00:18<03:05,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 24/263 batches (9.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  10%|▉         | 26/263 [00:20<03:04,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 26/263 batches (9.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  11%|█         | 28/263 [00:22<03:00,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 28/263 batches (10.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  11%|█▏        | 30/263 [00:23<03:01,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 30/263 batches (11.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  12%|█▏        | 32/263 [00:25<03:01,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 32/263 batches (12.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  13%|█▎        | 34/263 [00:26<02:58,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 34/263 batches (13.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  14%|█▎        | 36/263 [00:28<02:56,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 36/263 batches (13.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  14%|█▍        | 38/263 [00:29<02:56,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 38/263 batches (14.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  15%|█▌        | 40/263 [00:31<02:55,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 40/263 batches (15.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  16%|█▌        | 42/263 [00:32<02:51,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 42/263 batches (16.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  17%|█▋        | 44/263 [00:34<02:48,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 44/263 batches (16.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  17%|█▋        | 46/263 [00:36<02:50,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 46/263 batches (17.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  18%|█▊        | 48/263 [00:37<02:48,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 48/263 batches (18.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  19%|█▉        | 50/263 [00:39<02:47,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 50/263 batches (19.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  20%|█▉        | 52/263 [00:40<02:48,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 52/263 batches (19.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  21%|██        | 54/263 [00:42<02:45,  1.26it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 54/263 batches (20.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  21%|██▏       | 56/263 [00:43<02:40,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 56/263 batches (21.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  22%|██▏       | 58/263 [00:45<02:40,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 58/263 batches (22.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  23%|██▎       | 60/263 [00:47<02:35,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 60/263 batches (22.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  24%|██▎       | 62/263 [00:48<02:33,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 62/263 batches (23.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  24%|██▍       | 64/263 [00:50<02:32,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 64/263 batches (24.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  25%|██▌       | 66/263 [00:51<02:30,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 66/263 batches (25.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  26%|██▌       | 68/263 [00:53<02:28,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 68/263 batches (25.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  27%|██▋       | 70/263 [00:54<02:28,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 70/263 batches (26.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  27%|██▋       | 72/263 [00:56<02:26,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 72/263 batches (27.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  28%|██▊       | 74/263 [00:57<02:26,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 74/263 batches (28.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  29%|██▉       | 76/263 [00:59<02:25,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 76/263 batches (29.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  30%|██▉       | 78/263 [01:00<02:26,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 78/263 batches (29.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  30%|███       | 80/263 [01:02<02:25,  1.26it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 80/263 batches (30.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  31%|███       | 82/263 [01:04<02:22,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 82/263 batches (31.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  32%|███▏      | 84/263 [01:05<02:23,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 84/263 batches (32.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  33%|███▎      | 86/263 [01:07<02:19,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 86/263 batches (32.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  33%|███▎      | 88/263 [01:08<02:17,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 88/263 batches (33.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  34%|███▍      | 90/263 [01:10<02:20,  1.23it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 90/263 batches (34.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  35%|███▍      | 92/263 [01:12<02:17,  1.24it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 92/263 batches (35.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  36%|███▌      | 94/263 [01:13<02:15,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 94/263 batches (35.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  37%|███▋      | 96/263 [01:15<02:11,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 96/263 batches (36.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  37%|███▋      | 98/263 [01:16<02:09,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 98/263 batches (37.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  38%|███▊      | 100/263 [01:18<02:09,  1.26it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 100/263 batches (38.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  39%|███▉      | 102/263 [01:20<02:09,  1.24it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 102/263 batches (38.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  40%|███▉      | 104/263 [01:21<02:06,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 104/263 batches (39.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  40%|████      | 106/263 [01:23<02:03,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 106/263 batches (40.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  41%|████      | 108/263 [01:24<02:02,  1.26it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 108/263 batches (41.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  42%|████▏     | 110/263 [01:26<02:00,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 110/263 batches (41.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  43%|████▎     | 112/263 [01:27<01:57,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 112/263 batches (42.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  43%|████▎     | 114/263 [01:29<01:57,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 114/263 batches (43.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  44%|████▍     | 116/263 [01:31<01:55,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 116/263 batches (44.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  45%|████▍     | 118/263 [01:32<01:51,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 118/263 batches (45.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  46%|████▌     | 120/263 [01:34<01:49,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 120/263 batches (45.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  46%|████▋     | 122/263 [01:35<01:47,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 122/263 batches (46.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  47%|████▋     | 124/263 [01:37<01:46,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 124/263 batches (47.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  48%|████▊     | 126/263 [01:38<01:46,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 126/263 batches (48.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  49%|████▊     | 128/263 [01:40<01:44,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 128/263 batches (48.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  49%|████▉     | 130/263 [01:41<01:44,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 130/263 batches (49.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  50%|█████     | 132/263 [01:43<01:42,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 132/263 batches (50.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  51%|█████     | 134/263 [01:44<01:40,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 134/263 batches (51.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  52%|█████▏    | 136/263 [01:46<01:37,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 136/263 batches (51.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  52%|█████▏    | 138/263 [01:48<01:36,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 138/263 batches (52.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  53%|█████▎    | 140/263 [01:49<01:34,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 140/263 batches (53.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  54%|█████▍    | 142/263 [01:51<01:32,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 142/263 batches (54.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  55%|█████▍    | 144/263 [01:52<01:29,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 144/263 batches (54.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  56%|█████▌    | 146/263 [01:54<01:29,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 146/263 batches (55.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  56%|█████▋    | 148/263 [01:55<01:28,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 148/263 batches (56.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  57%|█████▋    | 150/263 [01:57<01:26,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 150/263 batches (57.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  58%|█████▊    | 152/263 [01:58<01:27,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 152/263 batches (57.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  59%|█████▊    | 154/263 [02:00<01:25,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 154/263 batches (58.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  59%|█████▉    | 156/263 [02:01<01:23,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 156/263 batches (59.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  60%|██████    | 158/263 [02:03<01:21,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 158/263 batches (60.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  61%|██████    | 160/263 [02:05<01:20,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 160/263 batches (61.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  62%|██████▏   | 162/263 [02:06<01:18,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 162/263 batches (61.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  62%|██████▏   | 164/263 [02:08<01:17,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 164/263 batches (62.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  63%|██████▎   | 166/263 [02:09<01:14,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 166/263 batches (63.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  64%|██████▍   | 168/263 [02:11<01:14,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 168/263 batches (64.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  65%|██████▍   | 170/263 [02:12<01:12,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 170/263 batches (64.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  65%|██████▌   | 172/263 [02:14<01:21,  1.12it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 172/263 batches (65.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  66%|██████▌   | 174/263 [02:16<01:14,  1.20it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 174/263 batches (66.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  67%|██████▋   | 176/263 [02:17<01:10,  1.24it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 176/263 batches (67.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  68%|██████▊   | 178/263 [02:19<01:06,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 178/263 batches (67.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  68%|██████▊   | 180/263 [02:21<01:04,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 180/263 batches (68.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  69%|██████▉   | 182/263 [02:22<01:02,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 182/263 batches (69.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  70%|██████▉   | 184/263 [02:24<01:00,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 184/263 batches (70.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  71%|███████   | 186/263 [02:25<00:59,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 186/263 batches (70.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  71%|███████▏  | 188/263 [02:27<00:58,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 188/263 batches (71.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  72%|███████▏  | 190/263 [02:28<00:56,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 190/263 batches (72.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  73%|███████▎  | 192/263 [02:30<00:54,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 192/263 batches (73.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  74%|███████▍  | 194/263 [02:31<00:53,  1.30it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 194/263 batches (73.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  75%|███████▍  | 196/263 [02:33<00:50,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 196/263 batches (74.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  75%|███████▌  | 198/263 [02:34<00:48,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 198/263 batches (75.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  76%|███████▌  | 200/263 [02:36<00:47,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 200/263 batches (76.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  77%|███████▋  | 202/263 [02:37<00:45,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 202/263 batches (77.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  78%|███████▊  | 204/263 [02:39<00:43,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 204/263 batches (77.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  78%|███████▊  | 206/263 [02:40<00:42,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 206/263 batches (78.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  79%|███████▉  | 208/263 [02:42<00:40,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 208/263 batches (79.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  80%|███████▉  | 210/263 [02:43<00:39,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 210/263 batches (80.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  81%|████████  | 212/263 [02:45<00:38,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 212/263 batches (80.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  81%|████████▏ | 214/263 [02:46<00:36,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 214/263 batches (81.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  82%|████████▏ | 216/263 [02:48<00:35,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 216/263 batches (82.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  83%|████████▎ | 218/263 [02:49<00:33,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 218/263 batches (83.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  84%|████████▎ | 220/263 [02:51<00:32,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 220/263 batches (83.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  84%|████████▍ | 222/263 [02:52<00:30,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 222/263 batches (84.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  85%|████████▌ | 224/263 [02:54<00:29,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 224/263 batches (85.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  86%|████████▌ | 226/263 [02:55<00:27,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 226/263 batches (86.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  87%|████████▋ | 228/263 [02:57<00:26,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 228/263 batches (86.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  87%|████████▋ | 230/263 [02:58<00:24,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 230/263 batches (87.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  88%|████████▊ | 232/263 [03:00<00:23,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 232/263 batches (88.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  89%|████████▉ | 234/263 [03:01<00:21,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 234/263 batches (89.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  90%|████████▉ | 236/263 [03:03<00:20,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 236/263 batches (89.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  90%|█████████ | 238/263 [03:04<00:18,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 238/263 batches (90.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  91%|█████████▏| 240/263 [03:06<00:17,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 240/263 batches (91.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  92%|█████████▏| 242/263 [03:07<00:16,  1.27it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 242/263 batches (92.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  93%|█████████▎| 244/263 [03:09<00:14,  1.28it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 244/263 batches (93.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  94%|█████████▎| 246/263 [03:11<00:13,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 246/263 batches (93.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  94%|█████████▍| 248/263 [03:12<00:11,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 248/263 batches (94.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  95%|█████████▌| 250/263 [03:14<00:09,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 250/263 batches (95.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  96%|█████████▌| 252/263 [03:15<00:08,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 252/263 batches (96.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  97%|█████████▋| 254/263 [03:17<00:06,  1.31it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 254/263 batches (96.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  97%|█████████▋| 256/263 [03:18<00:05,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 256/263 batches (97.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  98%|█████████▊| 258/263 [03:20<00:03,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 258/263 batches (98.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches:  99%|█████████▉| 260/263 [03:21<00:02,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 260/263 batches (99.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches: 100%|█████████▉| 262/263 [03:23<00:00,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 262/263 batches (99.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 Test Batches: 100%|██████████| 263/263 [03:23<00:00,  1.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"MFCC features shape: (16800, 1, 32, 32)\nLFCC features shape: (16800, 1, 32, 32)\nChroma features shape: (16800, 1, 12, 32)\nLabels shape: (16800,)\nTotal T2 test samples after feature extraction: 16800\nTotal T2 test samples: 16800, Number of T2 test chunks: 27, T2 Test Chunk size: 646\nWarning: 642 samples will be padded due to chunking.\nPadded MFCC features shape: (17442, 1, 32, 32)\nPadded LFCC features shape: (17442, 1, 32, 32)\nPadded Chroma features shape: (17442, 1, 12, 32)\nPadded Labels shape: (17442,)\nSaved T2 test chunk 0: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 1: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 2: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 3: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 4: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 5: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 6: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 7: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 8: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 9: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 10: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 11: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 12: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 13: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 14: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 15: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 16: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 17: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 18: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 19: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 20: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 21: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 22: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 23: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 24: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 25: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nSaved T2 test chunk 26: MFCC shape (646, 1, 32, 32), LFCC shape (646, 1, 32, 32), Chroma shape (646, 1, 12, 32), y shape (646,)\nProcessed and saved 17442 T2 test audio samples in /kaggle/working/preprocessed_t2_test_chunks!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Preprocessing for Training and Validation folders","metadata":{}},{"cell_type":"code","source":"\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchaudio\nfrom torchaudio.transforms import MFCC, LFCC, Spectrogram\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}, GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n\n# T2 dataset path\nT2_PATH = \"/kaggle/input/mladdc-t2/T2/\"\n\n# Function to validate if a .wav file can be loaded\ndef validate_wav_file(file_path):\n    try:\n        waveform, sr = torchaudio.load(file_path)\n        if waveform.size(1) == 0:\n            print(f\"Skipping empty file: {file_path}\")\n            return False\n        return True\n    except Exception as e:\n        print(f\"Skipping invalid file: {file_path}, Error: {e}\")\n        return False\n\n# Function to collect T2 audio files and labels\ndef get_t2_audio_files_and_labels(data_split=\"train\"):\n    audio_files = []\n    labels = []\n    counts = {\"real\": 0, \"fake\": 0}\n\n    real_path = os.path.join(T2_PATH, data_split, \"real\")\n    fake_path = os.path.join(T2_PATH, data_split, \"deepfake\")\n\n    if not os.path.exists(real_path):\n        raise FileNotFoundError(f\"Real directory not found at {real_path}\")\n    if not os.path.exists(fake_path):\n        raise FileNotFoundError(f\"Fake directory not found at {fake_path}\")\n\n    for file in os.listdir(real_path):\n        if file.endswith(\".wav\"):\n            file_path = os.path.join(real_path, file)\n            if validate_wav_file(file_path):\n                audio_files.append(file_path)\n                labels.append(0)  # Real\n                counts[\"real\"] += 1\n\n    for file in os.listdir(fake_path):\n        if file.endswith(\".wav\"):\n            file_path = os.path.join(fake_path, file)\n            if validate_wav_file(file_path):\n                audio_files.append(file_path)\n                labels.append(1)  # Fake\n                counts[\"fake\"] += 1\n\n    print(f\"T2 {data_split} Counts: Real: {counts['real']}, Fake: {counts['fake']}\")\n    return audio_files, labels\n\n# Custom Chroma-STFT implementation\ndef compute_chroma_stft(waveforms, sample_rate=16000, n_fft=2048, hop_length=512, n_chroma=12):\n    spectrogram_transform = Spectrogram(n_fft=n_fft, hop_length=hop_length, power=2.0).to(device)\n    spec = spectrogram_transform(waveforms)\n    spec = spec.squeeze(1)\n    freqs = torch.linspace(0, sample_rate / 2, steps=spec.shape[1]).to(device)\n    chroma_freqs = torch.tensor([31.25 * (2 ** (i / 12)) for i in range(12 * 4)], device=device)\n    chroma_bins = torch.zeros((n_chroma, spec.shape[1]), device=device)\n    for i in range(n_chroma):\n        center = chroma_freqs[i::12]\n        for cf in center:\n            mask = (freqs >= cf / 1.06) & (freqs <= cf * 1.06)\n            chroma_bins[i] += mask.float()\n    chroma_bins /= chroma_bins.sum(dim=1, keepdim=True).clamp(min=1e-10)\n    chroma = torch.einsum('cf,bft->bct', chroma_bins, spec)\n    return chroma\n\n# Feature Extraction for T2 train/val set\ndef extract_t2_features_batch(file_paths, labels, batch_size=64, max_length=16000, data_split=\"train\"):\n    mfcc_results = []\n    lfcc_results = []\n    chroma_results = []\n    valid_labels = []\n\n    mfcc_transform = MFCC(\n        sample_rate=16000,\n        n_mfcc=32,\n        melkwargs={\"n_fft\": 2048, \"hop_length\": 512, \"n_mels\": 128}\n    ).to(device)\n    lfcc_transform = LFCC(\n        sample_rate=16000,\n        n_lfcc=32,\n        f_min=0,\n        f_max=8000,\n        n_filter=128,\n        speckwargs={\"n_fft\": 2048, \"hop_length\": 512}\n    ).to(device)\n\n    total_batches = (len(file_paths) + batch_size - 1) // batch_size\n    log_interval = max(1, total_batches // 100)\n\n    for i in tqdm(range(0, len(file_paths), batch_size), desc=f\"Processing T2 {data_split} Batches\", total=total_batches):\n        if i % (log_interval * batch_size) == 0:\n            print(f\"Processed {i // batch_size}/{total_batches} batches ({(i / len(file_paths)) * 100:.1f}%)\")\n\n        batch_files = file_paths[i:i + batch_size]\n        batch_labels = labels[i:i + batch_size]\n        waveforms = []\n        valid_indices = []\n\n        for idx, (file_path, label) in enumerate(zip(batch_files, batch_labels)):\n            try:\n                waveform, sr = torchaudio.load(file_path)\n                if waveform.shape[0] > 1:\n                    waveform = waveform.mean(dim=0, keepdim=True)\n                if sr != 16000:\n                    waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n                if waveform.size(1) > max_length:\n                    waveform = waveform[:, :max_length]\n                elif waveform.size(1) < max_length:\n                    pad_size = max_length - waveform.size(1)\n                    waveform = torch.nn.functional.pad(waveform, (0, pad_size))\n                waveforms.append(waveform)\n                valid_indices.append(idx)\n            except Exception as e:\n                print(f\"Error loading {file_path}: {e}\")\n                continue\n\n        if not waveforms:\n            continue\n\n        waveforms = torch.nn.utils.rnn.pad_sequence(waveforms, batch_first=True).to(device)\n        mfccs = mfcc_transform(waveforms)\n        lfccs = lfcc_transform(waveforms)\n        chromas = compute_chroma_stft(waveforms, sample_rate=16000, n_fft=2048, hop_length=512, n_chroma=12)\n\n        # Debugging - recurring shape mismatch issues\n        target_frames = 32\n        for idx in valid_indices:\n            mfcc = mfccs[idx]\n            if len(mfcc.shape) == 3:\n                mfcc = mfcc.squeeze(0)\n            if mfcc.shape[1] > target_frames:\n                mfcc = mfcc[:, :target_frames]\n            elif mfcc.shape[1] < target_frames:\n                mfcc = torch.nn.functional.pad(mfcc, (0, target_frames - mfcc.shape[1]))\n            if mfcc.shape != (32, 32):\n                print(f\"Warning: MFCC shape after resize at index {idx}: {mfcc.shape}\")\n                continue\n            mfcc = mfcc.unsqueeze(0)\n            if mfcc.shape != (1, 32, 32):\n                print(f\"Warning: Final MFCC shape mismatch at index {idx}: {mfcc.shape}\")\n                continue\n            mfcc_results.append(mfcc.cpu().numpy())\n\n            lfcc = lfccs[idx]\n            if len(lfcc.shape) == 3:\n                lfcc = lfcc.squeeze(0)\n            if lfcc.shape[1] > target_frames:\n                lfcc = lfcc[:, :target_frames]\n            elif lfcc.shape[1] < target_frames:\n                lfcc = torch.nn.functional.pad(lfcc, (0, target_frames - lfcc.shape[1]))\n            if lfcc.shape != (32, 32):\n                print(f\"Warning: LFCC shape after resize at index {idx}: {lfcc.shape}\")\n                continue\n            lfcc = lfcc.unsqueeze(0)\n            if lfcc.shape != (1, 32, 32):\n                print(f\"Warning: Final LFCC shape mismatch at index {idx}: {lfcc.shape}\")\n                continue\n            lfcc_results.append(lfcc.cpu().numpy())\n\n            chroma = chromas[idx]\n            if len(chroma.shape) == 3:\n                chroma = chroma.squeeze(0)\n            if chroma.shape[1] > target_frames:\n                chroma = chroma[:, :target_frames]\n            elif chroma.shape[1] < target_frames:\n                chroma = torch.nn.functional.pad(chroma, (0, target_frames - chroma.shape[1]))\n            if chroma.shape != (12, 32):\n                print(f\"Warning: Chroma shape after resize at index {idx}: {chroma.shape}\")\n                continue\n            chroma = chroma.unsqueeze(0)\n            if chroma.shape != (1, 12, 32):\n                print(f\"Warning: Final Chroma shape mismatch at index {idx}: {chroma.shape}\")\n                continue\n            chroma_results.append(chroma.cpu().numpy())\n\n            valid_labels.append(batch_labels[idx])\n\n    return mfcc_results, lfcc_results, chroma_results, valid_labels\n\n# MFAAN Model\nclass MFAAN(nn.Module):\n    def __init__(self):\n        super(MFAAN, self).__init__()\n        self.path_mfcc = nn.Sequential(\n            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)\n        )\n        self.path_lfcc = nn.Sequential(\n            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)\n        )\n        self.path_chroma = nn.Sequential(\n            nn.Conv1d(in_channels=12, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)\n        )\n        self.fc1 = nn.Linear(32 * 8 * 3, 256)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, 2)\n\n    def forward(self, mfcc, lfcc, chroma):\n        mfcc = mfcc.squeeze(1)\n        lfcc = lfcc.squeeze(1)\n        chroma = chroma.squeeze(1)\n        mfcc_out = self.path_mfcc(mfcc)\n        lfcc_out = self.path_lfcc(lfcc)\n        chroma_out = self.path_chroma(chroma)\n        mfcc_flat = mfcc_out.view(mfcc_out.size(0), -1)\n        lfcc_flat = lfcc_out.view(lfcc_out.size(0), -1)\n        chroma_flat = chroma_out.view(chroma_out.size(0), -1)\n        fused = torch.cat((mfcc_flat, lfcc_flat, chroma_flat), dim=1)\n        x = F.relu(self.fc1(fused))\n        x = self.dropout(x)\n        output = self.fc2(x)\n        return output\n\n# Calculate and print model size\nmodel = MFAAN()\ntotal_params = sum(p.numel() for p in model.parameters())\nparam_size_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\nparam_size_mb = param_size_bytes / (1024 ** 2)\nprint(f\"\\nMFAAN Model Size:\")\nprint(f\"Total Parameters: {total_params:,}\")\nprint(f\"Parameter Size: {param_size_mb:.2f} MB\")\n\n# Preprocess T2 train and val sets\nfor data_split in [\"train\", \"val\"]:\n    print(f\"\\nProcessing T2 {data_split} split...\")\n    files, labels = get_t2_audio_files_and_labels(data_split)\n    print(f\"Total T2 {data_split} files: {len(files)}\")\n    print(f\"Label Distribution: Real (0): {sum(1 for label in labels if label == 0)} \"\n          f\"({sum(1 for label in labels if label == 0)/len(files)*100:.2f}%), \"\n          f\"Fake (1): {sum(1 for label in labels if label == 1)} \"\n          f\"({sum(1 for label in labels if label == 1)/len(files)*100:.2f}%)\")\n\n    mfcc_features, lfcc_features, chroma_features, labels = extract_t2_features_batch(\n        files, labels, batch_size=64, max_length=16000, data_split=data_split\n    )\n    mfcc_features = np.array(mfcc_features)\n    lfcc_features = np.array(lfcc_features)\n    chroma_features = np.array(chroma_features)\n    labels = np.array(labels)\n\n    print(f\"T2 {data_split} MFCC shape: {mfcc_features.shape}\")\n    print(f\"T2 {data_split} LFCC shape: {lfcc_features.shape}\")\n    print(f\"T2 {data_split} Chroma shape: {chroma_features.shape}\")\n    print(f\"T2 {data_split} Labels shape: {labels.shape}\")\n\n    # Validate alignment\n    if not (len(mfcc_features) == len(lfcc_features) == len(chroma_features) == len(labels)):\n        raise ValueError(f\"Mismatch in T2 {data_split} features and labels: \"\n                         f\"MFCC: {len(mfcc_features)}, LFCC: {len(lfcc_features)}, \"\n                         f\"Chroma: {len(chroma_features)}, Labels: {len(labels)}\")\n\n    # Save preprocessed data\n    output_dir = f\"/kaggle/working/preprocessed_t2_{data_split}\"\n    os.makedirs(output_dir, exist_ok=True)\n    for f in os.listdir(output_dir):\n        os.remove(os.path.join(output_dir, f))  # Clear existing files\n    np.save(os.path.join(output_dir, f\"t2_{data_split}_mfcc.npy\"), mfcc_features)\n    np.save(os.path.join(output_dir, f\"t2_{data_split}_lfcc.npy\"), lfcc_features)\n    np.save(os.path.join(output_dir, f\"t2_{data_split}_chroma.npy\"), chroma_features)\n    np.save(os.path.join(output_dir, f\"t2_{data_split}_labels.npy\"), labels)\n    print(f\"Saved preprocessed T2 {data_split} data to {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T11:01:41.253809Z","iopub.execute_input":"2025-04-24T11:01:41.254740Z","iopub.status.idle":"2025-04-24T12:46:27.865759Z","shell.execute_reply.started":"2025-04-24T11:01:41.254710Z","shell.execute_reply":"2025-04-24T12:46:27.865018Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda, GPU: Tesla T4\n\nMFAAN Model Size:\nTotal Parameters: 206,066\nParameter Size: 0.79 MB\n\nProcessing T2 train split...\nT2 train Counts: Real: 44800, Fake: 89600\nTotal T2 train files: 134400\nLabel Distribution: Real (0): 44800 (33.33%), Fake (1): 89600 (66.67%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   0%|          | 0/2100 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 0/2100 batches (0.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   1%|          | 21/2100 [00:24<40:15,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 21/2100 batches (1.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   2%|▏         | 42/2100 [00:48<39:23,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 42/2100 batches (2.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   3%|▎         | 63/2100 [01:13<39:08,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 63/2100 batches (3.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   4%|▍         | 84/2100 [01:36<37:11,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 84/2100 batches (4.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   5%|▌         | 105/2100 [02:01<36:53,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 105/2100 batches (5.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   6%|▌         | 126/2100 [02:25<36:35,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 126/2100 batches (6.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   7%|▋         | 147/2100 [02:49<37:12,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 147/2100 batches (7.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   8%|▊         | 168/2100 [03:13<37:00,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 168/2100 batches (8.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:   9%|▉         | 189/2100 [03:36<34:37,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 189/2100 batches (9.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  10%|█         | 210/2100 [04:00<36:05,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 210/2100 batches (10.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  11%|█         | 231/2100 [04:24<36:14,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 231/2100 batches (11.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  12%|█▏        | 252/2100 [04:48<35:54,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 252/2100 batches (12.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  13%|█▎        | 273/2100 [05:13<34:40,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 273/2100 batches (13.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  14%|█▍        | 294/2100 [05:37<34:47,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 294/2100 batches (14.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  15%|█▌        | 315/2100 [06:02<34:10,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 315/2100 batches (15.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  16%|█▌        | 336/2100 [06:27<33:14,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 336/2100 batches (16.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  17%|█▋        | 357/2100 [06:51<35:24,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 357/2100 batches (17.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  18%|█▊        | 378/2100 [07:15<33:16,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 378/2100 batches (18.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  19%|█▉        | 399/2100 [07:39<32:08,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 399/2100 batches (19.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  20%|██        | 420/2100 [08:04<32:35,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 420/2100 batches (20.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  21%|██        | 441/2100 [08:28<30:59,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 441/2100 batches (21.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  22%|██▏       | 462/2100 [08:52<32:50,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 462/2100 batches (22.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  23%|██▎       | 483/2100 [09:16<29:23,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 483/2100 batches (23.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  24%|██▍       | 504/2100 [09:40<30:50,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 504/2100 batches (24.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  25%|██▌       | 525/2100 [10:05<31:57,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 525/2100 batches (25.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  26%|██▌       | 546/2100 [10:30<29:08,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 546/2100 batches (26.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  27%|██▋       | 567/2100 [10:54<29:39,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 567/2100 batches (27.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  28%|██▊       | 588/2100 [11:18<29:17,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 588/2100 batches (28.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  29%|██▉       | 609/2100 [11:42<28:47,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 609/2100 batches (29.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  30%|███       | 630/2100 [12:07<28:01,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 630/2100 batches (30.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  31%|███       | 651/2100 [12:31<29:20,  1.21s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 651/2100 batches (31.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  32%|███▏      | 672/2100 [12:56<27:47,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 672/2100 batches (32.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  33%|███▎      | 693/2100 [13:20<26:14,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 693/2100 batches (33.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  34%|███▍      | 714/2100 [13:44<27:11,  1.18s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 714/2100 batches (34.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  35%|███▌      | 735/2100 [14:09<27:12,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 735/2100 batches (35.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  36%|███▌      | 756/2100 [14:33<25:25,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 756/2100 batches (36.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  37%|███▋      | 777/2100 [14:58<25:48,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 777/2100 batches (37.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  38%|███▊      | 798/2100 [15:22<25:23,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 798/2100 batches (38.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  39%|███▉      | 819/2100 [15:47<25:26,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 819/2100 batches (39.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  40%|████      | 840/2100 [16:12<25:27,  1.21s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 840/2100 batches (40.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  41%|████      | 861/2100 [16:37<24:33,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 861/2100 batches (41.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  42%|████▏     | 882/2100 [17:02<23:33,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 882/2100 batches (42.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  43%|████▎     | 903/2100 [17:26<23:01,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 903/2100 batches (43.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  44%|████▍     | 924/2100 [17:50<23:33,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 924/2100 batches (44.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  45%|████▌     | 945/2100 [18:14<21:22,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 945/2100 batches (45.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  46%|████▌     | 966/2100 [18:38<21:01,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 966/2100 batches (46.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  47%|████▋     | 987/2100 [19:02<20:36,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 987/2100 batches (47.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  48%|████▊     | 1008/2100 [19:26<20:05,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1008/2100 batches (48.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  49%|████▉     | 1029/2100 [19:49<20:15,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1029/2100 batches (49.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  50%|█████     | 1050/2100 [20:13<19:58,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1050/2100 batches (50.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  51%|█████     | 1071/2100 [20:37<19:16,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1071/2100 batches (51.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  52%|█████▏    | 1092/2100 [21:01<19:34,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1092/2100 batches (52.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  53%|█████▎    | 1113/2100 [21:25<18:26,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1113/2100 batches (53.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  54%|█████▍    | 1134/2100 [21:49<18:45,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1134/2100 batches (54.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  55%|█████▌    | 1155/2100 [22:12<17:45,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1155/2100 batches (55.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  56%|█████▌    | 1176/2100 [22:36<17:11,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1176/2100 batches (56.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  57%|█████▋    | 1197/2100 [23:00<17:23,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1197/2100 batches (57.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  58%|█████▊    | 1218/2100 [23:24<16:35,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1218/2100 batches (58.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  59%|█████▉    | 1239/2100 [23:47<16:16,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1239/2100 batches (59.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  60%|██████    | 1260/2100 [24:11<16:42,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1260/2100 batches (60.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  61%|██████    | 1281/2100 [24:35<15:09,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1281/2100 batches (61.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  62%|██████▏   | 1302/2100 [24:59<15:05,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1302/2100 batches (62.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  63%|██████▎   | 1323/2100 [25:23<14:52,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1323/2100 batches (63.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  64%|██████▍   | 1344/2100 [25:47<14:15,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1344/2100 batches (64.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  65%|██████▌   | 1365/2100 [26:10<13:49,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1365/2100 batches (65.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  66%|██████▌   | 1386/2100 [26:33<12:44,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1386/2100 batches (66.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  67%|██████▋   | 1407/2100 [26:57<12:47,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1407/2100 batches (67.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  68%|██████▊   | 1428/2100 [27:20<12:25,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1428/2100 batches (68.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  69%|██████▉   | 1449/2100 [27:44<12:07,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1449/2100 batches (69.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  70%|███████   | 1470/2100 [28:08<11:53,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1470/2100 batches (70.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  71%|███████   | 1491/2100 [28:31<10:48,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1491/2100 batches (71.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  72%|███████▏  | 1512/2100 [28:54<11:17,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1512/2100 batches (72.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  73%|███████▎  | 1533/2100 [29:18<10:16,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1533/2100 batches (73.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  74%|███████▍  | 1554/2100 [29:41<09:43,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1554/2100 batches (74.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  75%|███████▌  | 1575/2100 [30:05<09:55,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1575/2100 batches (75.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  76%|███████▌  | 1596/2100 [30:28<09:12,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1596/2100 batches (76.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  77%|███████▋  | 1617/2100 [30:52<09:34,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1617/2100 batches (77.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  78%|███████▊  | 1638/2100 [31:16<08:42,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1638/2100 batches (78.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  79%|███████▉  | 1659/2100 [31:39<08:47,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1659/2100 batches (79.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  80%|████████  | 1680/2100 [32:04<08:24,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1680/2100 batches (80.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  81%|████████  | 1701/2100 [32:27<07:06,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1701/2100 batches (81.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  82%|████████▏ | 1722/2100 [32:50<07:13,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1722/2100 batches (82.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  83%|████████▎ | 1743/2100 [33:14<06:25,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1743/2100 batches (83.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  84%|████████▍ | 1764/2100 [33:36<05:57,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1764/2100 batches (84.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  85%|████████▌ | 1785/2100 [33:59<05:51,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1785/2100 batches (85.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  86%|████████▌ | 1806/2100 [34:23<05:14,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1806/2100 batches (86.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  87%|████████▋ | 1827/2100 [34:46<05:20,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1827/2100 batches (87.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  88%|████████▊ | 1848/2100 [35:10<04:45,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1848/2100 batches (88.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  89%|████████▉ | 1869/2100 [35:32<04:06,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1869/2100 batches (89.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  90%|█████████ | 1890/2100 [35:56<04:09,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1890/2100 batches (90.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  91%|█████████ | 1911/2100 [36:19<03:31,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1911/2100 batches (91.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  92%|█████████▏| 1932/2100 [36:43<03:06,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1932/2100 batches (92.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  93%|█████████▎| 1953/2100 [37:06<02:44,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1953/2100 batches (93.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  94%|█████████▍| 1974/2100 [37:30<02:18,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1974/2100 batches (94.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  95%|█████████▌| 1995/2100 [37:53<02:00,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 1995/2100 batches (95.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  96%|█████████▌| 2016/2100 [38:17<01:31,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2016/2100 batches (96.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  97%|█████████▋| 2037/2100 [38:39<01:09,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2037/2100 batches (97.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  98%|█████████▊| 2058/2100 [39:03<00:47,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2058/2100 batches (98.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches:  99%|█████████▉| 2079/2100 [39:26<00:22,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2079/2100 batches (99.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 train Batches: 100%|██████████| 2100/2100 [39:49<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"T2 train MFCC shape: (134400, 1, 32, 32)\nT2 train LFCC shape: (134400, 1, 32, 32)\nT2 train Chroma shape: (134400, 1, 12, 32)\nT2 train Labels shape: (134400,)\nSaved preprocessed T2 train data to /kaggle/working/preprocessed_t2_train\n\nProcessing T2 val split...\nT2 val Counts: Real: 5600, Fake: 11200\nTotal T2 val files: 16800\nLabel Distribution: Real (0): 5600 (33.33%), Fake (1): 11200 (66.67%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   0%|          | 0/263 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Processed 0/263 batches (0.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   1%|          | 2/263 [00:02<05:00,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 2/263 batches (0.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   2%|▏         | 4/263 [00:04<05:00,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 4/263 batches (1.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   2%|▏         | 6/263 [00:07<05:06,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 6/263 batches (2.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   3%|▎         | 8/263 [00:09<04:53,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 8/263 batches (3.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   4%|▍         | 10/263 [00:11<05:05,  1.21s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 10/263 batches (3.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   5%|▍         | 12/263 [00:14<05:02,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 12/263 batches (4.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   5%|▌         | 14/263 [00:16<04:48,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 14/263 batches (5.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   6%|▌         | 16/263 [00:18<04:44,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 16/263 batches (6.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   7%|▋         | 18/263 [00:20<04:37,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 18/263 batches (6.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   8%|▊         | 20/263 [00:23<04:27,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 20/263 batches (7.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   8%|▊         | 22/263 [00:25<04:27,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 22/263 batches (8.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:   9%|▉         | 24/263 [00:27<04:36,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 24/263 batches (9.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  10%|▉         | 26/263 [00:29<04:26,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 26/263 batches (9.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  11%|█         | 28/263 [00:32<04:18,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 28/263 batches (10.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  11%|█▏        | 30/263 [00:34<04:23,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 30/263 batches (11.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  12%|█▏        | 32/263 [00:36<04:18,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 32/263 batches (12.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  13%|█▎        | 34/263 [00:39<04:22,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 34/263 batches (13.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  14%|█▎        | 36/263 [00:41<04:15,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 36/263 batches (13.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  14%|█▍        | 38/263 [00:43<04:05,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 38/263 batches (14.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  15%|█▌        | 40/263 [00:45<04:12,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 40/263 batches (15.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  16%|█▌        | 42/263 [00:48<04:12,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 42/263 batches (16.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  17%|█▋        | 44/263 [00:50<04:10,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 44/263 batches (16.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  17%|█▋        | 46/263 [00:52<04:04,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 46/263 batches (17.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  18%|█▊        | 48/263 [00:54<04:01,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 48/263 batches (18.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  19%|█▉        | 50/263 [00:57<03:58,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 50/263 batches (19.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  20%|█▉        | 52/263 [00:59<03:58,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 52/263 batches (19.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  21%|██        | 54/263 [01:01<03:59,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 54/263 batches (20.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  21%|██▏       | 56/263 [01:03<03:56,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 56/263 batches (21.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  22%|██▏       | 58/263 [01:06<03:52,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 58/263 batches (22.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  23%|██▎       | 60/263 [01:08<03:53,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 60/263 batches (22.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  24%|██▎       | 62/263 [01:10<03:56,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 62/263 batches (23.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  24%|██▍       | 64/263 [01:13<03:56,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 64/263 batches (24.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  25%|██▌       | 66/263 [01:15<03:52,  1.18s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 66/263 batches (25.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  26%|██▌       | 68/263 [01:17<03:47,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 68/263 batches (25.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  27%|██▋       | 70/263 [01:20<03:35,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 70/263 batches (26.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  27%|██▋       | 72/263 [01:22<03:32,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 72/263 batches (27.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  28%|██▊       | 74/263 [01:24<03:29,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 74/263 batches (28.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  29%|██▉       | 76/263 [01:26<03:28,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 76/263 batches (29.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  30%|██▉       | 78/263 [01:28<03:23,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 78/263 batches (29.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  30%|███       | 80/263 [01:31<03:16,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 80/263 batches (30.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  31%|███       | 82/263 [01:33<03:13,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 82/263 batches (31.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  32%|███▏      | 84/263 [01:35<03:14,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 84/263 batches (32.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  33%|███▎      | 86/263 [01:37<03:09,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 86/263 batches (32.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  33%|███▎      | 88/263 [01:39<03:07,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 88/263 batches (33.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  34%|███▍      | 90/263 [01:41<03:14,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 90/263 batches (34.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  35%|███▍      | 92/263 [01:44<03:04,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 92/263 batches (35.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  36%|███▌      | 94/263 [01:46<02:59,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 94/263 batches (35.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  37%|███▋      | 96/263 [01:48<02:56,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 96/263 batches (36.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  37%|███▋      | 98/263 [01:50<02:54,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 98/263 batches (37.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  38%|███▊      | 100/263 [01:52<02:52,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 100/263 batches (38.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  39%|███▉      | 102/263 [01:54<02:49,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 102/263 batches (38.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  40%|███▉      | 104/263 [01:56<02:47,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 104/263 batches (39.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  40%|████      | 106/263 [01:58<02:49,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 106/263 batches (40.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  41%|████      | 108/263 [02:01<02:45,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 108/263 batches (41.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  42%|████▏     | 110/263 [02:03<02:46,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 110/263 batches (41.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  43%|████▎     | 112/263 [02:05<02:47,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 112/263 batches (42.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  43%|████▎     | 114/263 [02:07<02:44,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 114/263 batches (43.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  44%|████▍     | 116/263 [02:09<02:41,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 116/263 batches (44.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  45%|████▍     | 118/263 [02:12<02:44,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 118/263 batches (45.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  46%|████▌     | 120/263 [02:14<02:45,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 120/263 batches (45.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  46%|████▋     | 122/263 [02:16<02:39,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 122/263 batches (46.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  47%|████▋     | 124/263 [02:19<02:37,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 124/263 batches (47.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  48%|████▊     | 126/263 [02:21<02:34,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 126/263 batches (48.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  49%|████▊     | 128/263 [02:23<02:34,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 128/263 batches (48.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  49%|████▉     | 130/263 [02:25<02:28,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 130/263 batches (49.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  50%|█████     | 132/263 [02:28<02:26,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 132/263 batches (50.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  51%|█████     | 134/263 [02:30<02:21,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 134/263 batches (51.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  52%|█████▏    | 136/263 [02:32<02:18,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 136/263 batches (51.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  52%|█████▏    | 138/263 [02:34<02:15,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 138/263 batches (52.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  53%|█████▎    | 140/263 [02:36<02:14,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 140/263 batches (53.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  54%|█████▍    | 142/263 [02:38<02:10,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 142/263 batches (54.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  55%|█████▍    | 144/263 [02:41<02:10,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 144/263 batches (54.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  56%|█████▌    | 146/263 [02:43<02:05,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 146/263 batches (55.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  56%|█████▋    | 148/263 [02:45<02:02,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 148/263 batches (56.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  57%|█████▋    | 150/263 [02:47<01:58,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 150/263 batches (57.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  58%|█████▊    | 152/263 [02:49<01:57,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 152/263 batches (57.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  59%|█████▊    | 154/263 [02:51<01:55,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 154/263 batches (58.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  59%|█████▉    | 156/263 [02:53<01:53,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 156/263 batches (59.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  60%|██████    | 158/263 [02:55<01:52,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 158/263 batches (60.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  61%|██████    | 160/263 [02:58<01:50,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 160/263 batches (61.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  62%|██████▏   | 162/263 [03:00<01:47,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 162/263 batches (61.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  62%|██████▏   | 164/263 [03:02<01:46,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 164/263 batches (62.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  63%|██████▎   | 166/263 [03:04<01:46,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 166/263 batches (63.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  64%|██████▍   | 168/263 [03:07<01:56,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 168/263 batches (64.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  65%|██████▍   | 170/263 [03:09<01:48,  1.16s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 170/263 batches (64.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  65%|██████▌   | 172/263 [03:11<01:44,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 172/263 batches (65.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  66%|██████▌   | 174/263 [03:13<01:38,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 174/263 batches (66.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  67%|██████▋   | 176/263 [03:16<01:37,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 176/263 batches (67.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  68%|██████▊   | 178/263 [03:18<01:37,  1.15s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 178/263 batches (67.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  68%|██████▊   | 180/263 [03:20<01:32,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 180/263 batches (68.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  69%|██████▉   | 182/263 [03:22<01:30,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 182/263 batches (69.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  70%|██████▉   | 184/263 [03:25<01:26,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 184/263 batches (70.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  71%|███████   | 186/263 [03:27<01:24,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 186/263 batches (70.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  71%|███████▏  | 188/263 [03:29<01:21,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 188/263 batches (71.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  72%|███████▏  | 190/263 [03:31<01:17,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 190/263 batches (72.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  73%|███████▎  | 192/263 [03:33<01:14,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 192/263 batches (73.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  74%|███████▍  | 194/263 [03:35<01:13,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 194/263 batches (73.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  75%|███████▍  | 196/263 [03:37<01:11,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 196/263 batches (74.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  75%|███████▌  | 198/263 [03:40<01:08,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 198/263 batches (75.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  76%|███████▌  | 200/263 [03:42<01:07,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 200/263 batches (76.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  77%|███████▋  | 202/263 [03:44<01:04,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 202/263 batches (77.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  78%|███████▊  | 204/263 [03:46<01:01,  1.04s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 204/263 batches (77.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  78%|███████▊  | 206/263 [03:48<01:01,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 206/263 batches (78.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  79%|███████▉  | 208/263 [03:50<00:58,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 208/263 batches (79.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  80%|███████▉  | 210/263 [03:52<00:57,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 210/263 batches (80.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  81%|████████  | 212/263 [03:55<00:55,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 212/263 batches (80.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  81%|████████▏ | 214/263 [03:57<00:52,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 214/263 batches (81.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  82%|████████▏ | 216/263 [03:59<00:49,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 216/263 batches (82.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  83%|████████▎ | 218/263 [04:01<00:48,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 218/263 batches (83.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  84%|████████▎ | 220/263 [04:03<00:47,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 220/263 batches (83.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  84%|████████▍ | 222/263 [04:05<00:44,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 222/263 batches (84.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  85%|████████▌ | 224/263 [04:08<00:43,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 224/263 batches (85.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  86%|████████▌ | 226/263 [04:10<00:40,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 226/263 batches (86.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  87%|████████▋ | 228/263 [04:12<00:38,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 228/263 batches (86.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  87%|████████▋ | 230/263 [04:14<00:35,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 230/263 batches (87.6%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  88%|████████▊ | 232/263 [04:16<00:33,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 232/263 batches (88.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  89%|████████▉ | 234/263 [04:18<00:31,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 234/263 batches (89.1%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  90%|████████▉ | 236/263 [04:21<00:30,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 236/263 batches (89.9%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  90%|█████████ | 238/263 [04:23<00:27,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 238/263 batches (90.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  91%|█████████▏| 240/263 [04:25<00:25,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 240/263 batches (91.4%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  92%|█████████▏| 242/263 [04:27<00:23,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 242/263 batches (92.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  93%|█████████▎| 244/263 [04:29<00:20,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 244/263 batches (93.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  94%|█████████▎| 246/263 [04:32<00:18,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 246/263 batches (93.7%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  94%|█████████▍| 248/263 [04:34<00:16,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 248/263 batches (94.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  95%|█████████▌| 250/263 [04:36<00:13,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 250/263 batches (95.2%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  96%|█████████▌| 252/263 [04:38<00:11,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 252/263 batches (96.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  97%|█████████▋| 254/263 [04:40<00:09,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 254/263 batches (96.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  97%|█████████▋| 256/263 [04:42<00:07,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 256/263 batches (97.5%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  98%|█████████▊| 258/263 [04:44<00:05,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 258/263 batches (98.3%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches:  99%|█████████▉| 260/263 [04:46<00:03,  1.05s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 260/263 batches (99.0%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches: 100%|█████████▉| 262/263 [04:48<00:01,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 262/263 batches (99.8%)\n","output_type":"stream"},{"name":"stderr","text":"Processing T2 val Batches: 100%|██████████| 263/263 [04:49<00:00,  1.10s/it]\n","output_type":"stream"},{"name":"stdout","text":"T2 val MFCC shape: (16800, 1, 32, 32)\nT2 val LFCC shape: (16800, 1, 32, 32)\nT2 val Chroma shape: (16800, 1, 12, 32)\nT2 val Labels shape: (16800,)\nSaved preprocessed T2 val data to /kaggle/working/preprocessed_t2_val\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, roc_curve, confusion_matrix\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}, GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n\n# MFAAN Model\nclass MFAAN(nn.Module):\n    def __init__(self):\n        super(MFAAN, self).__init__()\n        self.path_mfcc = nn.Sequential(\n            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)\n        )\n        self.path_lfcc = nn.Sequential(\n            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)\n        )\n        self.path_chroma = nn.Sequential(\n            nn.Conv1d(in_channels=12, out_channels=16, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2),\n            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.Dropout(0.4),\n            nn.MaxPool1d(kernel_size=2, stride=2)\n        )\n        self.fc1 = nn.Linear(32 * 8 * 3, 256)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, 2)\n\n    def forward(self, mfcc, lfcc, chroma):\n        mfcc = mfcc.squeeze(1)\n        lfcc = lfcc.squeeze(1)\n        chroma = chroma.squeeze(1)\n        mfcc_out = self.path_mfcc(mfcc)\n        lfcc_out = self.path_lfcc(lfcc)\n        chroma_out = self.path_chroma(chroma)\n        mfcc_flat = mfcc_out.view(mfcc_out.size(0), -1)\n        lfcc_flat = lfcc_out.view(lfcc_out.size(0), -1)\n        chroma_flat = chroma_out.view(chroma_out.size(0), -1)\n        fused = torch.cat((mfcc_flat, lfcc_flat, chroma_flat), dim=1)\n        x = F.relu(self.fc1(fused))\n        x = self.dropout(x)\n        output = self.fc2(x)\n        return output\n\nmodel = MFAAN()\ntotal_params = sum(p.numel() for p in model.parameters())\nparam_size_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\nparam_size_mb = param_size_bytes / (1024 ** 2)\nprint(f\"\\nMFAAN Model Size:\")\nprint(f\"Total Parameters: {total_params:,}\")\nprint(f\"Parameter Size: {param_size_mb:.2f} MB\")\n\n# Custom Dataset Class for Train/Val\nclass T2AudioDataset(Dataset):\n    def __init__(self, mfcc_features, lfcc_features, chroma_features, labels):\n        self.mfcc_features = mfcc_features\n        self.lfcc_features = lfcc_features\n        self.chroma_features = chroma_features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        mfcc = torch.FloatTensor(self.mfcc_features[idx])\n        lfcc = torch.FloatTensor(self.lfcc_features[idx])\n        chroma = torch.FloatTensor(self.chroma_features[idx])\n        label = torch.LongTensor([self.labels[idx]])[0]\n\n        mfcc = (mfcc - mfcc.mean()) / (mfcc.std() + 1e-8)\n        lfcc = (lfcc - lfcc.mean()) / (lfcc.std() + 1e-8)\n        chroma = (chroma - chroma.mean()) / (chroma.std() + 1e-8)\n\n        return mfcc, lfcc, chroma, label\n\n# Custom Dataset Class for Test\nclass AudioDataset(Dataset):\n    def __init__(self, chunk_dir, chunk_indices, dataset_type=\"test\"):\n        self.chunk_dir = chunk_dir\n        self.dataset_type = dataset_type\n        if not os.path.exists(chunk_dir):\n            raise FileNotFoundError(f\"Chunk directory {chunk_dir} does not exist.\")\n        \n        self.chunk_files = sorted([f for f in os.listdir(chunk_dir) if f.startswith(\"t2_test_mfcc_chunk_\") and f.endswith(\".npy\")])\n        if not self.chunk_files:\n            raise FileNotFoundError(f\"No MFCC chunk files found in {chunk_dir}.\")\n        \n        print(f\"Found {len(self.chunk_files)} chunk files in {chunk_dir}. First few: {self.chunk_files[:5]}\")\n        \n        self.chunk_size = 646\n        self.num_chunks = len(self.chunk_files)\n        self.total_samples = self.num_chunks * self.chunk_size\n        self.indices = [idx for idx in chunk_indices if idx < self.total_samples]\n        \n        if not self.indices:\n            raise ValueError(f\"No valid indices for {self.dataset_type} dataset. Total samples: {self.total_samples}.\")\n        \n        print(f\"Dataset ({self.dataset_type}) initialized with {len(self.indices)} samples.\")\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, idx):\n        if idx >= len(self.indices):\n            raise IndexError(f\"Index {idx} is out of bounds for dataset with length {len(self.indices)}\")\n        \n        global_idx = self.indices[idx]\n        chunk_idx = global_idx // self.chunk_size\n        local_idx = global_idx % self.chunk_size\n        \n        mfcc_chunk = np.load(os.path.join(self.chunk_dir, f\"t2_test_mfcc_chunk_{chunk_idx}.npy\"), mmap_mode='r')\n        lfcc_chunk = np.load(os.path.join(self.chunk_dir, f\"t2_test_lfcc_chunk_{chunk_idx}.npy\"), mmap_mode='r')\n        chroma_chunk = np.load(os.path.join(self.chunk_dir, f\"t2_test_chroma_chunk_{chunk_idx}.npy\"), mmap_mode='r')\n        y_chunk = np.load(os.path.join(self.chunk_dir, f\"t2_test_y_chunk_{chunk_idx}.npy\"), mmap_mode='r')\n        \n        mfcc = torch.FloatTensor(mfcc_chunk[local_idx])\n        lfcc = torch.FloatTensor(lfcc_chunk[local_idx])\n        chroma = torch.FloatTensor(chroma_chunk[local_idx])\n        y = torch.LongTensor([y_chunk[local_idx]])[0]\n        \n        mfcc = (mfcc - mfcc.mean()) / (mfcc.std() + 1e-8)\n        lfcc = (lfcc - lfcc.mean()) / (lfcc.std() + 1e-8)\n        chroma = (chroma - chroma.mean()) / (chroma.std() + 1e-8)\n        \n        return mfcc, lfcc, chroma, y\n\n# Compute eer\ndef compute_eer(labels, scores):\n    fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n    fnr = 1 - tpr\n    eer = fpr[np.nanargmin(np.absolute(fnr - fpr))]\n    return eer\n\n# Load preprocessed train and val data\ntry:\n    train_dataset = T2AudioDataset(\n        np.load(\"/kaggle/working/preprocessed_t2_train/t2_train_mfcc.npy\"),\n        np.load(\"/kaggle/working/preprocessed_t2_train/t2_train_lfcc.npy\"),\n        np.load(\"/kaggle/working/preprocessed_t2_train/t2_train_chroma.npy\"),\n        np.load(\"/kaggle/working/preprocessed_t2_train/t2_train_labels.npy\")\n    )\n    val_dataset = T2AudioDataset(\n        np.load(\"/kaggle/working/preprocessed_t2_val/t2_val_mfcc.npy\"),\n        np.load(\"/kaggle/working/preprocessed_t2_val/t2_val_lfcc.npy\"),\n        np.load(\"/kaggle/working/preprocessed_t2_val/t2_val_chroma.npy\"),\n        np.load(\"/kaggle/working/preprocessed_t2_val/t2_val_labels.npy\")\n    )\nexcept FileNotFoundError as e:\n    raise FileNotFoundError(f\"Preprocessed train/val data not found. Run the preprocessing cell first: {e}\")\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\nprint(f\"Train dataset size: {len(train_dataset)}, Val dataset size: {len(val_dataset)}\")\n\n# Compute class weights for imbalanced data\ntrain_labels = np.load(\"/kaggle/working/preprocessed_t2_train/t2_train_labels.npy\")\nclass_counts = np.bincount(train_labels)\nclass_weights = torch.FloatTensor([1.0 / class_counts[i] for i in range(2)]).to(device)\nclass_weights = class_weights / class_weights.sum() * 2  # Normalize\nprint(f\"Class weights (Real, Fake): {class_weights.tolist()}\")\n\nmodel = MFAAN().to(device)\ntry:\n    model.load_state_dict(torch.load(\"/kaggle/working/mfaan_best.pth\"))  # Load pre-trained weights\nexcept FileNotFoundError:\n    print(\"Pre-trained model not found. Starting fine-tuning from scratch.\")\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Low lr for fine-tuning\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\n# Fine-tuning loop\nnum_epochs = 20\nbest_val_eer = float(\"inf\")\nbest_model_path = \"/kaggle/working/mfaan_t2_finetuned.pth\"\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    train_preds = []\n    train_labels = []\n    for mfcc, lfcc, chroma, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n        mfcc, lfcc, chroma, labels = mfcc.to(device), lfcc.to(device), chroma.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(mfcc, lfcc, chroma)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        train_preds.extend(predicted.cpu().numpy())\n        train_labels.extend(labels.cpu().numpy())\n\n    train_acc = accuracy_score(train_labels, train_preds)\n    train_loss /= len(train_loader)\n\n    model.eval()\n    val_loss = 0.0\n    val_preds = []\n    val_scores = []\n    val_labels = []\n    with torch.no_grad():\n        for mfcc, lfcc, chroma, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n            mfcc, lfcc, chroma, labels = mfcc.to(device), lfcc.to(device), chroma.to(device), labels.to(device)\n            outputs = model(mfcc, lfcc, chroma)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            probs = F.softmax(outputs, dim=1)[:, 1]\n            _, predicted = torch.max(outputs, 1)\n            val_preds.extend(predicted.cpu().numpy())\n            val_scores.extend(probs.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n\n    val_acc = accuracy_score(val_labels, val_preds)\n    val_eer = compute_eer(val_labels, val_scores)\n    val_loss /= len(val_loader)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%, Val EER: {val_eer*100:.2f}%\")\n\n    if val_eer < best_val_eer:\n        best_val_eer = val_eer\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"Saved best model with Val EER: {best_val_eer*100:.2f}%\")\n\nprint(f\"Fine-tuning complete. Best model saved to {best_model_path}\")\n\n# Test the fine-tuned model\nmodel.load_state_dict(torch.load(best_model_path))\nmodel.eval()\nprint(\"\\nLoaded fine-tuned model for testing.\")\n\n# Create test dataset and loader\nchunk_dir = \"/kaggle/working/preprocessed_t2_test_chunks\"\ntotal_t2_test_samples = 16800  # Actual samples, excluding padding\ntest_indices = list(range(total_t2_test_samples))\nt2_test_dataset = AudioDataset(chunk_dir, test_indices, dataset_type=\"test\")\nt2_test_loader = DataLoader(t2_test_dataset, batch_size=32, shuffle=False, num_workers=0)\n\n# Evaluate on T2 test set\ntest_preds = []\ntest_scores = []\ntest_labels = []\nwith torch.no_grad():\n    for mfcc, lfcc, chroma, labels in tqdm(t2_test_loader, desc=\"Evaluating T2 Test Set\"):\n        mfcc, lfcc, chroma, labels = mfcc.to(device), lfcc.to(device), chroma.to(device), labels.to(device)\n        outputs = model(mfcc, lfcc, chroma)\n        probs = F.softmax(outputs, dim=1)[:, 1]\n        _, predicted = torch.max(outputs, 1)\n        test_preds.extend(predicted.cpu().numpy())\n        test_scores.extend(probs.cpu().numpy())\n        test_labels.extend(labels.cpu().numpy())\n\ntest_acc = accuracy_score(test_labels, test_preds)\ntest_eer = compute_eer(test_labels, test_scores)\ncm = confusion_matrix(test_labels, test_preds)\nper_class_acc = cm.diagonal() / cm.sum(axis=1)\n\n# Print results\nprint(f\"\\nFinal T2 Test Accuracy: {test_acc * 100:.2f}%\")\nprint(f\"Final T2 Test EER: {test_eer * 100:.2f}%\")\nprint(f\"Per-class accuracy (Real, Fake): {per_class_acc * 100}\")\n\n# Compare with baseline\nbaseline_accuracy = 68.44\nbaseline_eer = 40.9\nprint(f\"\\nBaseline Accuracy (T2): {baseline_accuracy:.2f}%, Baseline EER: {baseline_eer:.2f}%\")\nprint(\"Model vs. Baseline:\")\nprint(f\"Accuracy: {'Outperforms' if test_acc * 100 > baseline_accuracy else 'Does not outperform'} \"\n      f\"(Model: {test_acc * 100:.2f}%, Baseline: {baseline_accuracy:.2f}%)\")\nprint(f\"EER: {'Outperforms' if test_eer * 100 < baseline_eer else 'Does not outperform'} \"\n      f\"(Model: {test_eer * 100:.2f}%, Baseline: {baseline_eer:.2f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:21:36.269111Z","iopub.execute_input":"2025-04-24T13:21:36.269712Z","iopub.status.idle":"2025-04-24T13:37:33.550505Z","shell.execute_reply.started":"2025-04-24T13:21:36.269690Z","shell.execute_reply":"2025-04-24T13:37:33.549566Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda, GPU: Tesla T4\n\nMFAAN Model Size:\nTotal Parameters: 206,066\nParameter Size: 0.79 MB\nTrain dataset size: 134400, Val dataset size: 16800\nClass weights (Real, Fake): [1.3333333730697632, 0.6666666865348816]\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 97.09it/s] \nEpoch 1/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 150.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20:\nTrain Loss: 0.2703, Train Acc: 88.65%\nVal Loss: 0.3135, Val Acc: 86.97%, Val EER: 10.20%\nSaved best model with Val EER: 10.20%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.64it/s] \nEpoch 2/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 153.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20:\nTrain Loss: 0.1972, Train Acc: 92.13%\nVal Loss: 0.2405, Val Acc: 90.53%, Val EER: 8.34%\nSaved best model with Val EER: 8.34%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.04it/s]\nEpoch 3/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 146.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20:\nTrain Loss: 0.1824, Train Acc: 92.63%\nVal Loss: 0.2455, Val Acc: 90.49%, Val EER: 8.48%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.44it/s]\nEpoch 4/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 150.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20:\nTrain Loss: 0.1722, Train Acc: 93.12%\nVal Loss: 0.2355, Val Acc: 90.26%, Val EER: 7.64%\nSaved best model with Val EER: 7.64%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.65it/s] \nEpoch 5/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 147.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20:\nTrain Loss: 0.1676, Train Acc: 93.28%\nVal Loss: 0.2216, Val Acc: 91.61%, Val EER: 7.52%\nSaved best model with Val EER: 7.52%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.96it/s] \nEpoch 6/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 148.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20:\nTrain Loss: 0.1626, Train Acc: 93.54%\nVal Loss: 0.2127, Val Acc: 91.79%, Val EER: 7.57%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.19it/s] \nEpoch 7/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 151.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20:\nTrain Loss: 0.1586, Train Acc: 93.77%\nVal Loss: 0.2026, Val Acc: 92.47%, Val EER: 7.16%\nSaved best model with Val EER: 7.16%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.83it/s]\nEpoch 8/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 147.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20:\nTrain Loss: 0.1547, Train Acc: 93.86%\nVal Loss: 0.2948, Val Acc: 87.99%, Val EER: 8.52%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.48it/s] \nEpoch 9/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 149.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20:\nTrain Loss: 0.1508, Train Acc: 94.07%\nVal Loss: 0.2307, Val Acc: 91.11%, Val EER: 7.68%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.24it/s] \nEpoch 10/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 147.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20:\nTrain Loss: 0.1499, Train Acc: 94.01%\nVal Loss: 0.2355, Val Acc: 91.02%, Val EER: 7.75%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.79it/s] \nEpoch 11/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 151.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20:\nTrain Loss: 0.1459, Train Acc: 94.19%\nVal Loss: 0.2140, Val Acc: 91.46%, Val EER: 7.14%\nSaved best model with Val EER: 7.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20 [Train]: 100%|██████████| 4200/4200 [00:42<00:00, 97.89it/s] \nEpoch 12/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 154.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20:\nTrain Loss: 0.1450, Train Acc: 94.26%\nVal Loss: 0.2470, Val Acc: 90.02%, Val EER: 7.70%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.78it/s] \nEpoch 13/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 151.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20:\nTrain Loss: 0.1436, Train Acc: 94.30%\nVal Loss: 0.2180, Val Acc: 91.54%, Val EER: 7.86%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 97.31it/s] \nEpoch 14/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 150.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20:\nTrain Loss: 0.1409, Train Acc: 94.34%\nVal Loss: 0.2358, Val Acc: 90.49%, Val EER: 7.96%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 97.26it/s] \nEpoch 15/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 154.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20:\nTrain Loss: 0.1389, Train Acc: 94.42%\nVal Loss: 0.2510, Val Acc: 90.04%, Val EER: 8.07%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20 [Train]: 100%|██████████| 4200/4200 [00:42<00:00, 97.75it/s] \nEpoch 16/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 151.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20:\nTrain Loss: 0.1387, Train Acc: 94.48%\nVal Loss: 0.2437, Val Acc: 90.27%, Val EER: 7.29%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20 [Train]: 100%|██████████| 4200/4200 [00:42<00:00, 97.72it/s] \nEpoch 17/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 150.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20:\nTrain Loss: 0.1376, Train Acc: 94.48%\nVal Loss: 0.2496, Val Acc: 89.43%, Val EER: 7.14%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20 [Train]: 100%|██████████| 4200/4200 [00:42<00:00, 97.95it/s] \nEpoch 18/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 152.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20:\nTrain Loss: 0.1368, Train Acc: 94.51%\nVal Loss: 0.2224, Val Acc: 90.85%, Val EER: 7.18%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.90it/s] \nEpoch 19/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 149.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20:\nTrain Loss: 0.1348, Train Acc: 94.60%\nVal Loss: 0.2188, Val Acc: 91.32%, Val EER: 7.52%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20 [Train]: 100%|██████████| 4200/4200 [00:43<00:00, 96.81it/s] \nEpoch 20/20 [Val]: 100%|██████████| 525/525 [00:03<00:00, 150.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20:\nTrain Loss: 0.1358, Train Acc: 94.55%\nVal Loss: 0.2610, Val Acc: 89.70%, Val EER: 8.45%\nFine-tuning complete. Best model saved to /kaggle/working/mfaan_t2_finetuned.pth\n\nLoaded fine-tuned model for testing.\nFound 27 chunk files in /kaggle/working/preprocessed_t2_test_chunks. First few: ['t2_test_mfcc_chunk_0.npy', 't2_test_mfcc_chunk_1.npy', 't2_test_mfcc_chunk_10.npy', 't2_test_mfcc_chunk_11.npy', 't2_test_mfcc_chunk_12.npy']\nDataset (test) initialized with 16800 samples.\n","output_type":"stream"},{"name":"stderr","text":"Evaluating T2 Test Set: 100%|██████████| 525/525 [00:16<00:00, 31.04it/s]","output_type":"stream"},{"name":"stdout","text":"\nFinal T2 Test Accuracy: 91.76%\nFinal T2 Test EER: 6.89%\nPer-class accuracy (Real, Fake): [95.85714286 89.71428571]\n\nBaseline Accuracy (T2): 68.44%, Baseline EER: 40.90%\nModel vs. Baseline:\nAccuracy: Outperforms (Model: 91.76%, Baseline: 68.44%)\nEER: Outperforms (Model: 6.89%, Baseline: 40.90%)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14}]}